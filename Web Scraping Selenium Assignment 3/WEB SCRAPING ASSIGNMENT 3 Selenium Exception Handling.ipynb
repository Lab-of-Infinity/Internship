{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a python program which searches all the product under a particular product vertical from www.amazon.in. The product verticals to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the title of Product you are interest in search :guitar\n"
     ]
    }
   ],
   "source": [
    "#connecting to the webdriver\n",
    "driver=webdriver.Chrome(r'C:\\chromedriver.exe')\n",
    "time.sleep(2)\n",
    "\n",
    "# Opening Amazon.in in chrome browser\n",
    "url='http://www.amazon.in/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# Taking input from user about product search\n",
    "User_input=input('Enter the title of Product you are interest in search :')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding search menu by xpath\n",
    "Search=driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]')\n",
    "# clearing any previous input in search bar\n",
    "Search.clear()\n",
    "# Feeding input specified by user to search menu through send keys\n",
    "Search.send_keys(User_input)\n",
    "# Finding Search button for clicking through xpath\n",
    "Search_button=driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]')\n",
    "# Clicking search button\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <em> 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product vertical has less than 3 pages in search results then scrape all the products available under that product vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“ </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Empty list to scrap data\n",
    "Brand =[]\n",
    "Product = []\n",
    "Rating =[]\n",
    "No_of_ratings =[]\n",
    "Price =[]\n",
    "Return =[]\n",
    "Excepted_delivery =[]\n",
    "Availability =[]\n",
    "Other_details =[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Scraping url of all product listed on first 3 pages</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL= []\n",
    "# range(0,3) used to scrape three pages on website\n",
    "for page in range(0,3):\n",
    "    url=driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "    for i in url:\n",
    "        URL.append(i.get_attribute('href'))\n",
    "    time.sleep(2)\n",
    "    # locating next page button and clicking\n",
    "    Nxt_page=driver.find_element_by_xpath('//li[@class=\"a-last\"][1]/a')\n",
    "    Nxt_page.click()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [41:51<00:00, 15.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Extracting Brand Name via Xpath\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath('//a[@id=\"bylineInfo\"]')\n",
    "        Brand.append(brand.text) \n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')\n",
    "        \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting product name via Xpath\n",
    "    try:\n",
    "        product =driver.find_element_by_xpath('//span[@id=\"productTitle\"]')\n",
    "        Product.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        Product.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting Rating via Xpath\n",
    "    try:\n",
    "        rating=driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-base\"]')\n",
    "        Rating.append(rating.text)\n",
    "    except NoSuchElementException:\n",
    "        Rating.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting No of Ratings via Xpath\n",
    "    try:\n",
    "        rating_count=driver.find_element_by_xpath('//span[@class=\"a-size-base a-color-secondary\"]')\n",
    "        No_of_ratings.append(rating_count.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_ratings.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting Price via Xpath\n",
    "    try:\n",
    "        price=driver.find_element_by_xpath('//span[@id=\"priceblock_dealprice\"]')\n",
    "        Price.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Price.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting Return or exchange detail via Xpath\n",
    "    try:\n",
    "        replacement=driver.find_element_by_xpath('//*[@id=\"RETURNS_POLICY\"]/span/div[2]/a')\n",
    "        Return.append(replacement.text)\n",
    "    except NoSuchElementException:\n",
    "        Return.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting Expected Delivery via Xpath\n",
    "    try:\n",
    "        delivery=driver.find_element_by_xpath('//div[@id=\"ddmDeliveryMessage\"]/b')\n",
    "        Excepted_delivery.append(delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        Excepted_delivery.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting Availability via Xath\n",
    "    try:\n",
    "        availability=driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-success\"]')\n",
    "        Availability.append(availability.text)\n",
    "    except NoSuchElementException:\n",
    "        Availability.append('-')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Extracting other details via Xpath\n",
    "    try:\n",
    "        other=driver.find_element_by_xpath('//ul[@class=\"a-unordered-list a-vertical a-spacing-mini\"]')\n",
    "        Other_details.append(other.text)\n",
    "    except NoSuchElementException:\n",
    "        Other_details.append('-')\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAmazon Festive Sale Guitar with exciting offers :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No. of ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Other Details</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visit the Guitar Bro Store</td>\n",
       "      <td>GUITAR BRO - COMBO (Blue Acoustic Guitar for B...</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "      <td>Total price:</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Oct 27 - 30</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>GUITAR BRO +20 mins FREE VIDEO Demo - is a lea...</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brand: Crizer</td>\n",
       "      <td>Crizer 4 String Guitar Children's Musical Inst...</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "      <td>Total price:</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Sunday, Oct 24</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>PROVIDES SCREEN FREE FUN: A junior scale 4 str...</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Visit the JUAREZ Store</td>\n",
       "      <td>Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>13,307 global ratings</td>\n",
       "      <td>₹1,999.00</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Saturday, Oct 23</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Black Glossy Finish, Number of Frets: 18, Acou...</td>\n",
       "      <td>https://www.amazon.in/Juarez-Acoustic-Cutaway-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visit the JUAREZ Store</td>\n",
       "      <td>Juarez Acoustic Guitar Kit, 38 Inch Cutaway, 3...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>4,481 global ratings</td>\n",
       "      <td>₹1,999.00</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Saturday, Oct 23</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Black glossy finish, number of frets: 18, acou...</td>\n",
       "      <td>https://www.amazon.in/JUAREZ-JRZ38C-Acoustic-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Visit the Intern Store</td>\n",
       "      <td>Intern INT-38C Acoustic Guitar Kit, With Bag, ...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>7,221 global ratings</td>\n",
       "      <td>₹1,990.00</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Saturday, Oct 23</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Great looks with an innovative design to produ...</td>\n",
       "      <td>https://www.amazon.in/Intern-INT-38C-Acoustic-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Brand: HRB MUSICALS</td>\n",
       "      <td>HRB MUSICALS {BEST COMBO ALL IN ONE PACK} GUIT...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Wednesday, Oct 27</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>CAPO- guitar capo for use in all types of guit...</td>\n",
       "      <td>https://www.amazon.in/HRB-MUSICALS-ALL-GUITAR-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Brand: MUSICAL STRING</td>\n",
       "      <td>Musical String New Acoustic Guitar 6 string, 2...</td>\n",
       "      <td>-</td>\n",
       "      <td>Total price:</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Tuesday, Oct 26</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>41 inch Acoustic Guitar 6-Strings, Right-Hande...</td>\n",
       "      <td>https://www.amazon.in/Musical-String-Acoustic-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Visit the VAULT Store</td>\n",
       "      <td>Vault ST1 Premium Electric Guitar - Metallic Blue</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "      <td>24 global ratings</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Saturday, Oct 23</td>\n",
       "      <td>Only 2 left in stock.</td>\n",
       "      <td>Sycamore Body\\nMaple neck\\nIndian Laurel fretb...</td>\n",
       "      <td>https://www.amazon.in/Vault-ST1-Premium-Electr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Visit the Ghime Store</td>\n",
       "      <td>Ghime Wooden Finish Acoustic Musical Guitar wi...</td>\n",
       "      <td>3 out of 5</td>\n",
       "      <td>Total price:</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Sunday, Oct 24</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>It is fully functional Guitar with all the tun...</td>\n",
       "      <td>https://www.amazon.in/Ghime-Acoustic-Musical-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Visit the Kadence Store</td>\n",
       "      <td>Kadence Guitar Acoustica Series, Electric Acou...</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "      <td>Total price:</td>\n",
       "      <td>₹6,174.00</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Tuesday, Oct 26</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Product Type : Acoustic Guitar Fretboard mater...</td>\n",
       "      <td>https://aax-eu.amazon.in/x/c/QkZ-Ud_nVedAaesmG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Brand  \\\n",
       "0    Visit the Guitar Bro Store   \n",
       "1                 Brand: Crizer   \n",
       "2        Visit the JUAREZ Store   \n",
       "3        Visit the JUAREZ Store   \n",
       "4        Visit the Intern Store   \n",
       "..                          ...   \n",
       "159         Brand: HRB MUSICALS   \n",
       "160       Brand: MUSICAL STRING   \n",
       "161       Visit the VAULT Store   \n",
       "162       Visit the Ghime Store   \n",
       "163     Visit the Kadence Store   \n",
       "\n",
       "                                               Product        Rating  \\\n",
       "0    GUITAR BRO - COMBO (Blue Acoustic Guitar for B...  3.7 out of 5   \n",
       "1    Crizer 4 String Guitar Children's Musical Inst...  3.7 out of 5   \n",
       "2    Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...    4 out of 5   \n",
       "3    Juarez Acoustic Guitar Kit, 38 Inch Cutaway, 3...    4 out of 5   \n",
       "4    Intern INT-38C Acoustic Guitar Kit, With Bag, ...    4 out of 5   \n",
       "..                                                 ...           ...   \n",
       "159  HRB MUSICALS {BEST COMBO ALL IN ONE PACK} GUIT...             -   \n",
       "160  Musical String New Acoustic Guitar 6 string, 2...             -   \n",
       "161  Vault ST1 Premium Electric Guitar - Metallic Blue  3.7 out of 5   \n",
       "162  Ghime Wooden Finish Acoustic Musical Guitar wi...    3 out of 5   \n",
       "163  Kadence Guitar Acoustica Series, Electric Acou...  3.9 out of 5   \n",
       "\n",
       "            No. of ratings      Price     Return/Exchange  Expected Delivery  \\\n",
       "0             Total price:          -  7 Days Replacement        Oct 27 - 30   \n",
       "1             Total price:          -  7 Days Replacement     Sunday, Oct 24   \n",
       "2    13,307 global ratings  ₹1,999.00  7 Days Replacement   Saturday, Oct 23   \n",
       "3     4,481 global ratings  ₹1,999.00  7 Days Replacement   Saturday, Oct 23   \n",
       "4     7,221 global ratings  ₹1,990.00  7 Days Replacement   Saturday, Oct 23   \n",
       "..                     ...        ...                 ...                ...   \n",
       "159                      -          -  7 Days Replacement  Wednesday, Oct 27   \n",
       "160           Total price:          -  7 Days Replacement    Tuesday, Oct 26   \n",
       "161      24 global ratings          -  7 Days Replacement   Saturday, Oct 23   \n",
       "162           Total price:          -  7 Days Replacement     Sunday, Oct 24   \n",
       "163           Total price:  ₹6,174.00  7 Days Replacement    Tuesday, Oct 26   \n",
       "\n",
       "              Availability                                      Other Details  \\\n",
       "0                In stock.  GUITAR BRO +20 mins FREE VIDEO Demo - is a lea...   \n",
       "1                In stock.  PROVIDES SCREEN FREE FUN: A junior scale 4 str...   \n",
       "2                In stock.  Black Glossy Finish, Number of Frets: 18, Acou...   \n",
       "3                In stock.  Black glossy finish, number of frets: 18, acou...   \n",
       "4                In stock.  Great looks with an innovative design to produ...   \n",
       "..                     ...                                                ...   \n",
       "159              In stock.  CAPO- guitar capo for use in all types of guit...   \n",
       "160              In stock.  41 inch Acoustic Guitar 6-Strings, Right-Hande...   \n",
       "161  Only 2 left in stock.  Sycamore Body\\nMaple neck\\nIndian Laurel fretb...   \n",
       "162              In stock.  It is fully functional Guitar with all the tun...   \n",
       "163              In stock.  Product Type : Acoustic Guitar Fretboard mater...   \n",
       "\n",
       "                                                   URL  \n",
       "0    https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "1    https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "2    https://www.amazon.in/Juarez-Acoustic-Cutaway-...  \n",
       "3    https://www.amazon.in/JUAREZ-JRZ38C-Acoustic-S...  \n",
       "4    https://www.amazon.in/Intern-INT-38C-Acoustic-...  \n",
       "..                                                 ...  \n",
       "159  https://www.amazon.in/HRB-MUSICALS-ALL-GUITAR-...  \n",
       "160  https://www.amazon.in/Musical-String-Acoustic-...  \n",
       "161  https://www.amazon.in/Vault-ST1-Premium-Electr...  \n",
       "162  https://www.amazon.in/Ghime-Acoustic-Musical-A...  \n",
       "163  https://aax-eu.amazon.in/x/c/QkZ-Ud_nVedAaesmG...  \n",
       "\n",
       "[164 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Guitar=pd.DataFrame({'Brand':Brand,'Product':Product,'Rating':Rating,'No. of ratings':No_of_ratings,'Price':Price,\n",
    "                        'Return/Exchange':Return,'Expected Delivery':Excepted_delivery,'Availability':Availability,\n",
    "                        'Other Details':Other_details,'URL':URL})\n",
    "print('\\033[1m'+'Amazon Festive Sale Guitar with exciting offers :'+'\\033[0m')\n",
    "Guitar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Write a python program to access the search bar and search button on images.google.com and scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in Chrome browser\n",
    "url='https://images.google.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b><em> Searching and extracting for Fruits.</em><b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Search bar website by class\n",
    "Search=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "# Clearing any previous input in search bar\n",
    "Search.clear()\n",
    "# Feeding input 'Fruits' in search bar\n",
    "Search.send_keys('Fruits')\n",
    "# Finding Search button for clicking through class name\n",
    "Search_button=driver.find_element_by_class_name('zgAlFc')\n",
    "# Clicking search button\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolling window using ScrollBy method from 0 pixel to 25000 pixel\n",
    "driver.execute_script(\"window.scrollBy(0,25000)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=[]\n",
    "images= driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            URL.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 63 of 100 images\n",
      "Downloading 64 of 100 images\n",
      "Downloading 65 of 100 images\n",
      "Downloading 66 of 100 images\n",
      "Downloading 67 of 100 images\n",
      "Downloading 68 of 100 images\n",
      "Downloading 69 of 100 images\n",
      "Downloading 70 of 100 images\n",
      "Downloading 71 of 100 images\n",
      "Downloading 72 of 100 images\n",
      "Downloading 73 of 100 images\n",
      "Downloading 74 of 100 images\n",
      "Downloading 75 of 100 images\n",
      "Downloading 76 of 100 images\n",
      "Downloading 77 of 100 images\n",
      "Downloading 78 of 100 images\n",
      "Downloading 79 of 100 images\n",
      "Downloading 80 of 100 images\n",
      "Downloading 81 of 100 images\n",
      "Downloading 82 of 100 images\n",
      "Downloading 83 of 100 images\n",
      "Downloading 84 of 100 images\n",
      "Downloading 85 of 100 images\n",
      "Downloading 86 of 100 images\n",
      "Downloading 87 of 100 images\n",
      "Downloading 88 of 100 images\n",
      "Downloading 89 of 100 images\n",
      "Downloading 90 of 100 images\n",
      "Downloading 91 of 100 images\n",
      "Downloading 92 of 100 images\n",
      "Downloading 93 of 100 images\n",
      "Downloading 94 of 100 images\n",
      "Downloading 95 of 100 images\n",
      "Downloading 96 of 100 images\n",
      "Downloading 97 of 100 images\n",
      "Downloading 98 of 100 images\n",
      "Downloading 99 of 100 images\n"
     ]
    }
   ],
   "source": [
    "images = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\Infinity\\Fliprobbo\\WebScraping Assignment 3 Selenium\\Fruits\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Searching and extracting for Cars.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Search bar website by class\n",
    "Search=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "# Clearing any previous input in search bar\n",
    "Search.clear()\n",
    "# Feeding input 'Cars' in search bar\n",
    "Search.send_keys('Cars')\n",
    "# Finding Search button for clicking through class name\n",
    "Search_button=driver.find_element_by_class_name('zgAlFc')\n",
    "# Clicking search button\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolling window using ScrollBy method from 0 pixel to 25000 pixel\n",
    "driver.execute_script(\"window.scrollBy(0,50000)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=[]\n",
    "images= driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            URL.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 63 of 100 images\n",
      "Downloading 64 of 100 images\n",
      "Downloading 65 of 100 images\n",
      "Downloading 66 of 100 images\n",
      "Downloading 67 of 100 images\n",
      "Downloading 68 of 100 images\n",
      "Downloading 69 of 100 images\n",
      "Downloading 70 of 100 images\n",
      "Downloading 71 of 100 images\n",
      "Downloading 72 of 100 images\n",
      "Downloading 73 of 100 images\n",
      "Downloading 74 of 100 images\n",
      "Downloading 75 of 100 images\n",
      "Downloading 76 of 100 images\n",
      "Downloading 77 of 100 images\n",
      "Downloading 78 of 100 images\n",
      "Downloading 79 of 100 images\n",
      "Downloading 80 of 100 images\n",
      "Downloading 81 of 100 images\n",
      "Downloading 82 of 100 images\n",
      "Downloading 83 of 100 images\n",
      "Downloading 84 of 100 images\n",
      "Downloading 85 of 100 images\n",
      "Downloading 86 of 100 images\n",
      "Downloading 87 of 100 images\n",
      "Downloading 88 of 100 images\n",
      "Downloading 89 of 100 images\n",
      "Downloading 90 of 100 images\n",
      "Downloading 91 of 100 images\n",
      "Downloading 92 of 100 images\n",
      "Downloading 93 of 100 images\n",
      "Downloading 94 of 100 images\n",
      "Downloading 95 of 100 images\n",
      "Downloading 96 of 100 images\n",
      "Downloading 97 of 100 images\n",
      "Downloading 98 of 100 images\n",
      "Downloading 99 of 100 images\n"
     ]
    }
   ],
   "source": [
    "images = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\Infinity\\Fliprobbo\\WebScraping Assignment 3 Selenium\\Cars\" +str(i)+ \".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Searching and extracting for Machine Learning.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in Chrome browser\n",
    "url='https://images.google.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Search bar website by class\n",
    "Search=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "# Clearing any previous input in search bar\n",
    "Search.clear()\n",
    "# Feeding input 'Machine Learning' in search bar\n",
    "Search.send_keys('Machine Learning')\n",
    "# Finding Search button for clicking through class name\n",
    "Search_button=driver.find_element_by_class_name('zgAlFc')\n",
    "# Clicking search button\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolling window using ScrollBy method from 0 pixel to 50000 pixel\n",
    "driver.execute_script(\"window.scrollBy(0,50000)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=[]\n",
    "images= driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            URL.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 63 of 100 images\n",
      "Downloading 64 of 100 images\n",
      "Downloading 65 of 100 images\n",
      "Downloading 66 of 100 images\n",
      "Downloading 67 of 100 images\n",
      "Downloading 68 of 100 images\n",
      "Downloading 69 of 100 images\n",
      "Downloading 70 of 100 images\n",
      "Downloading 71 of 100 images\n",
      "Downloading 72 of 100 images\n",
      "Downloading 73 of 100 images\n",
      "Downloading 74 of 100 images\n",
      "Downloading 75 of 100 images\n",
      "Downloading 76 of 100 images\n",
      "Downloading 77 of 100 images\n",
      "Downloading 78 of 100 images\n",
      "Downloading 79 of 100 images\n",
      "Downloading 80 of 100 images\n",
      "Downloading 81 of 100 images\n",
      "Downloading 82 of 100 images\n",
      "Downloading 83 of 100 images\n",
      "Downloading 84 of 100 images\n",
      "Downloading 85 of 100 images\n",
      "Downloading 86 of 100 images\n",
      "Downloading 87 of 100 images\n",
      "Downloading 88 of 100 images\n",
      "Downloading 89 of 100 images\n",
      "Downloading 90 of 100 images\n",
      "Downloading 91 of 100 images\n",
      "Downloading 92 of 100 images\n",
      "Downloading 93 of 100 images\n",
      "Downloading 94 of 100 images\n",
      "Downloading 95 of 100 images\n",
      "Downloading 96 of 100 images\n",
      "Downloading 97 of 100 images\n",
      "Downloading 98 of 100 images\n",
      "Downloading 99 of 100 images\n"
     ]
    }
   ],
   "source": [
    "images = driver.find_elements_by_xpath('//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\Infinity\\Fliprobbo\\WebScraping Assignment 3 Selenium\\Machine Learning\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. Incase if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing require libary\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in Chrome browser\n",
    "url='http://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    login_window = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "    login_window.click()\n",
    "except NoSuchElementException:\n",
    "    print('Login Window is not present')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Search bar website by xpath\n",
    "Search=driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]/input')\n",
    "# Clearing any previous input in search bar\n",
    "Search.clear()\n",
    "# Feeding input 'Oneplus' in search bar\n",
    "Search.send_keys('Iphone Mobile')\n",
    "# Finding Search button for clicking through class name\n",
    "Search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "# Clicking search button\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making empty list to scrape data\n",
    "Brand =[]\n",
    "Smartphone =[]\n",
    "Colour =[]\n",
    "Storage_Rom =[]\n",
    "Primary_camera=[]\n",
    "Secondary_camera=[]\n",
    "Display_size=[]\n",
    "Display_resolution=[]\n",
    "Processor =[]\n",
    "Processor_cores=[]\n",
    "Battery_capacity=[]\n",
    "Price =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=[]\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]')\n",
    "for i in url:\n",
    "    Href=i.get_attribute('href')\n",
    "    URL.append(Href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [05:54<00:00, 14.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Expanding specification table by clicking on read more button\n",
    "    try:\n",
    "        Read_more=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _1FH0tX\"]')\n",
    "        Read_more.click()\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print('NoSuchElementException Occur')\n",
    "        pass\n",
    "    \n",
    "    # Extracting Brand Name via Xpath\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath('//span[@class=\"B_NuCI\"]')\n",
    "        Brand.append(brand.text.split()[0])\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')\n",
    "        \n",
    "    # Extracting Smartphone Model via Xpath\n",
    "    try:\n",
    "        smartphone=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        Smartphone.append(smartphone.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Smartphone.append('-')\n",
    "        \n",
    "    # Extracting Colour via Xpath\n",
    "    try:\n",
    "        colour=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        Colour.append(colour.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Colour.append('-')\n",
    "    \n",
    "    # Extracting Storage Rom via Xpath\n",
    "    try:\n",
    "        Rom=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][4]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "        Storage_Rom.append(Rom.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Storage_Rom.append('Not Mention')\n",
    "        \n",
    "    # Extracting primary camera detail via Xpath\n",
    "    try:\n",
    "        primary_camera=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        Primary_camera.append(primary_camera.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Primary_camera.append('Not Mention')\n",
    "        \n",
    "    # Extracting Secondary Camera detail via Xpath\n",
    "    try:\n",
    "        secondary_cam=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table/tbody/tr[5]/td[2]/ul/li')\n",
    "        Secondary_camera.append(secondary_cam.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Secondary_camera.append('Not Mention')\n",
    "    \n",
    "    # Extracting Display size via Xpath\n",
    "    try:\n",
    "        display=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "        Display_size.append(display.text)\n",
    "    except NoSuchElementException:\n",
    "        Display_size.append('-')\n",
    "    \n",
    "    # Extracting Display Resolution via Xpath\n",
    "    try:\n",
    "        resolution=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        Display_resolution.append(resolution.text)\n",
    "    except NoSuchElementException:\n",
    "        Display_resolution.append('-')\n",
    "    \n",
    "    # Extracting processor detail via xpath\n",
    "    try:\n",
    "        processor=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "        Processor.append(processor.text)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Processor.append('-')\n",
    "        \n",
    "    # Extracting Processor core via xpath\n",
    "    try:\n",
    "        core=driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        Processor_cores.append(core.text)\n",
    "    except NoSuchElementException:\n",
    "        Processor_cores.append('Not Mention')\n",
    "    \n",
    "    #Extracting Price via X path\n",
    "    try:\n",
    "        price=driver.find_element_by_xpath('//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        Price.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Price.append('Not Mention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFlipkart Iphone Models :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Smartphone</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Price</th>\n",
       "      <th>Storage Rom</th>\n",
       "      <th>Primary Camera</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Display Resolution</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Processor Cores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPLE</td>\n",
       "      <td>iPhone 12</td>\n",
       "      <td>Purple</td>\n",
       "      <td>₹60,199</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12MP + 12MP</td>\n",
       "      <td>15.49 cm (6.1 inch)</td>\n",
       "      <td>2532 x 1170 Pixels</td>\n",
       "      <td>A14 Bionic Chip with Next Generation Neural En...</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPLE</td>\n",
       "      <td>iPhone 12</td>\n",
       "      <td>White</td>\n",
       "      <td>₹60,199</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12MP + 12MP</td>\n",
       "      <td>15.49 cm (6.1 inch)</td>\n",
       "      <td>2532 x 1170 Pixels</td>\n",
       "      <td>A14 Bionic Chip with Next Generation Neural En...</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPLE</td>\n",
       "      <td>iPhone 12</td>\n",
       "      <td>Blue</td>\n",
       "      <td>₹53,999</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>12MP + 12MP</td>\n",
       "      <td>15.49 cm (6.1 inch)</td>\n",
       "      <td>2532 x 1170 Pixels</td>\n",
       "      <td>A14 Bionic Chip with Next Generation Neural En...</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPLE</td>\n",
       "      <td>iPhone 12</td>\n",
       "      <td>White</td>\n",
       "      <td>₹53,999</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>12MP + 12MP</td>\n",
       "      <td>15.49 cm (6.1 inch)</td>\n",
       "      <td>2532 x 1170 Pixels</td>\n",
       "      <td>A14 Bionic Chip with Next Generation Neural En...</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APPLE</td>\n",
       "      <td>iPhone 12</td>\n",
       "      <td>Blue</td>\n",
       "      <td>₹60,199</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12MP + 12MP</td>\n",
       "      <td>15.49 cm (6.1 inch)</td>\n",
       "      <td>2532 x 1170 Pixels</td>\n",
       "      <td>A14 Bionic Chip with Next Generation Neural En...</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand Smartphone  Colour    Price Storage Rom Primary Camera  \\\n",
       "0  APPLE  iPhone 12  Purple  ₹60,199      128 GB    12MP + 12MP   \n",
       "1  APPLE  iPhone 12   White  ₹60,199      128 GB    12MP + 12MP   \n",
       "2  APPLE  iPhone 12    Blue  ₹53,999       64 GB    12MP + 12MP   \n",
       "3  APPLE  iPhone 12   White  ₹53,999       64 GB    12MP + 12MP   \n",
       "4  APPLE  iPhone 12    Blue  ₹60,199      128 GB    12MP + 12MP   \n",
       "\n",
       "          Display Size  Display Resolution  \\\n",
       "0  15.49 cm (6.1 inch)  2532 x 1170 Pixels   \n",
       "1  15.49 cm (6.1 inch)  2532 x 1170 Pixels   \n",
       "2  15.49 cm (6.1 inch)  2532 x 1170 Pixels   \n",
       "3  15.49 cm (6.1 inch)  2532 x 1170 Pixels   \n",
       "4  15.49 cm (6.1 inch)  2532 x 1170 Pixels   \n",
       "\n",
       "                                           Processor Processor Cores  \n",
       "0  A14 Bionic Chip with Next Generation Neural En...     Not Mention  \n",
       "1  A14 Bionic Chip with Next Generation Neural En...     Not Mention  \n",
       "2  A14 Bionic Chip with Next Generation Neural En...     Not Mention  \n",
       "3  A14 Bionic Chip with Next Generation Neural En...     Not Mention  \n",
       "4  A14 Bionic Chip with Next Generation Neural En...     Not Mention  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Iphone=pd.DataFrame({'Brand':Brand,'Smartphone':Smartphone,'Colour':Colour,'Price':Price,\n",
    "                        'Storage Rom':Storage_Rom,'Primary Camera':Primary_camera,'Display Size':Display_size,\n",
    "                        'Display Resolution':Display_resolution,'Processor':Processor,'Processor Cores':Processor_cores})\n",
    "print('\\033[1m'+'Flipkart Iphone Models :'+'\\033[0m')\n",
    "Iphone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in chrome browser\n",
    "url='https://www.google.co.in/maps'\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding search menu by xpath\n",
    "Search=driver.find_element_by_id(\"searchboxinput\") \n",
    "# clearing any previous input in search bar\n",
    "Search.clear()\n",
    "# Feeding input specified by user to search menu through send keys\n",
    "Search.send_keys('Nashik')\n",
    "# Finding Search button for clicking through xpath\n",
    "Search_button=driver.find_element_by_id(\"searchbox-searchbutton\")  \n",
    "# Clicking search button\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current url : https://www.google.co.in/maps/place/Nashik,+Maharashtra/@19.972286,73.7532623,14z/data=!4m5!3m4!1s0x3bddd290b09914b3:0xcb07845d9d28215c!8m2!3d19.9974533!4d73.7898023\n"
     ]
    }
   ],
   "source": [
    "current_url=driver.current_url\n",
    "print('Current url :',current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude of given Location: 19.972286\n",
      "Longitude of given Location: 73.7532623\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if \"@\" in current_url:\n",
    "        location=current_url.split('@')[1].split(',*/data')[0].split(',')\n",
    "        location\n",
    "        print('Latitude of given Location:',location[0])\n",
    "        print('Longitude of given Location:',location[1])\n",
    "except:\n",
    "    print('Location detail not found in url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in chrome browser\n",
    "url='https://www.trak.in'\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking funding deals button\n",
    "Funding_deals=driver.find_element_by_xpath('//li[@id=\"menu-item-51510\"]/a').get_attribute('href')\n",
    "driver.get(Funding_deals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Empty list to scrap data\n",
    "Date=[]\n",
    "Startup=[]\n",
    "Industry=[]\n",
    "Sub_vertical=[]\n",
    "City=[]\n",
    "Investor=[]\n",
    "Investment_type=[]\n",
    "Amount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(48,51)):\n",
    "    # Extracting Date from table\n",
    "    try:\n",
    "        date=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[2]'.format(i))\n",
    "        for j in date:\n",
    "            Date.append(j.text)\n",
    "    except:\n",
    "        Date.append('NA')\n",
    "        \n",
    "    # Extracting startup name via xpath\n",
    "    try:\n",
    "        startup=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[3]'.format(i))\n",
    "        for j in startup:\n",
    "            Startup.append(j.text)\n",
    "    except:\n",
    "        Startup.append('NA')\n",
    "    \n",
    "    # Extracting Industry vertical via Xpath\n",
    "    try:\n",
    "        industry=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[4]'.format(i))\n",
    "        for j in industry:\n",
    "            Industry.append(j.text)\n",
    "    except:\n",
    "        Industry.append('NA')\n",
    "    \n",
    "    # Extracting subvertical via xpath\n",
    "    try:\n",
    "        subvertical=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[5]'.format(i))\n",
    "        for j in subvertical:\n",
    "            Sub_vertical.append(j.text)\n",
    "    except:\n",
    "        Sub_vertical.append('NA')\n",
    "    \n",
    "    # Extracting city/location via xpath\n",
    "    try:\n",
    "        city=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[6]'.format(i))\n",
    "        for j in city:\n",
    "            City.append(j.text)\n",
    "    except:\n",
    "        City.append('NA')\n",
    "        \n",
    "    # Extracting Investor via xpath\n",
    "    try:\n",
    "        investor=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[7]'.format(i))\n",
    "        for j in investor:\n",
    "            Investor.append(j.text)\n",
    "    except:\n",
    "        Investor.append('NA')\n",
    "        \n",
    "    # Extracting Investment type via xpath\n",
    "    try:\n",
    "        investment_type=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[8]'.format(i))\n",
    "        for j in investment_type:\n",
    "            Investment_type.append(j.text)\n",
    "    except:\n",
    "        Investment_type.append('NA')\n",
    "        \n",
    "    # Extracting Amount type via xpath\n",
    "    try:\n",
    "        amount=driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[9]'.format(i))\n",
    "        for j in amount:\n",
    "            Amount.append(j.text)\n",
    "    except:\n",
    "        Amount.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFunding deals in second quarter (i.e. July 20 –September 20) :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Company</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>City</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Walmart Inc</td>\n",
       "      <td>M&amp;A</td>\n",
       "      <td>1,200,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Vedantu</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Coatue Management</td>\n",
       "      <td>Series D</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Crio</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Learning Platform for Developers</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>021 Capital</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>934,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>goDutch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Group Payments</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Matrix India,Y Combinator, Global Founders Cap...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Mystifly</td>\n",
       "      <td>Airfare Marketplace</td>\n",
       "      <td>Ticketing, Airline Retailing, and Post-Ticketi...</td>\n",
       "      <td>Singapore and Bangalore</td>\n",
       "      <td>Recruit Co. Ltd.</td>\n",
       "      <td>pre-Series B</td>\n",
       "      <td>3,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>JetSynthesys</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Adar Poonawalla and Kris Gopalakrishnan.</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/07/2020</td>\n",
       "      <td>gigIndia</td>\n",
       "      <td>Marketplace</td>\n",
       "      <td>Crowd Sourcing, Freelance</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Incubate Fund India and Beyond Next Ventures</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>974,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>PumPumPum</td>\n",
       "      <td>Automotive Rental</td>\n",
       "      <td>Used Car-leasing platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Early Adapters Syndicate</td>\n",
       "      <td>Seed</td>\n",
       "      <td>292,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>FLYX</td>\n",
       "      <td>OTT Player</td>\n",
       "      <td>Streaming Social Network</td>\n",
       "      <td>New York and Delhi</td>\n",
       "      <td>Raj Mishra, founder of AIT Global Inc</td>\n",
       "      <td>pre-Seed</td>\n",
       "      <td>200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Open Appliances Pvt. Ltd.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Internet-of-Things Security Solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Unicorn India Ventures</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15/08/2020</td>\n",
       "      <td>Practo</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Health care and Wellness</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>A1A Company</td>\n",
       "      <td>Series F</td>\n",
       "      <td>32,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Medlife</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Prasid Uno Family Trust and SC Credit Fund</td>\n",
       "      <td></td>\n",
       "      <td>23,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>HungerBox</td>\n",
       "      <td>FoodTech</td>\n",
       "      <td>Online Food Delivery Service</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>One97, Sabre Partners Trust, Pratithi Investme...</td>\n",
       "      <td>Series D1</td>\n",
       "      <td>1,560,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>Hyper-local Logistics</td>\n",
       "      <td>Online Delivery Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Existing Backers</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>Terra.do</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Climate School, E-learning</td>\n",
       "      <td>Stanford, California,</td>\n",
       "      <td>Stanford Angels and Entrepreneurs (India), BEE...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/08/2020</td>\n",
       "      <td>Classplus</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>E-learning, Online Tutoring</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Falcon Edge</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>upto 15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14/08/2020</td>\n",
       "      <td>Niyo</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Niyo Solutions Inc.</td>\n",
       "      <td></td>\n",
       "      <td>6,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/08/2020</td>\n",
       "      <td>ZestMoney</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Primrose Hills Ventures</td>\n",
       "      <td></td>\n",
       "      <td>10,670,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>FreshToHome</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Ascent Capital</td>\n",
       "      <td>Venture</td>\n",
       "      <td>16,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Eduvanz</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sequoia India, Unitus</td>\n",
       "      <td>Series A</td>\n",
       "      <td>5,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Skincare &amp; Haircare</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Curiosity Platform for Kids</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>Melorra</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Jewelry Store</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Shadow Holdings, Lightbox.</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>upto 8,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>1mg</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Gaja Capital, Tata Capital, Partners Group</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>mfine</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>On-Demand Healthcare Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Caretech Pte Inc</td>\n",
       "      <td>Series B</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>Apna</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Recruitment Platform</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Lightspeed India and Sequoia Capital India</td>\n",
       "      <td>Series A</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>Railofy</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>WL &amp; RAC protection platform</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>950,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date            Startup Company  \\\n",
       "0   15/07/2020                   Flipkart   \n",
       "1   16/07/2020                    Vedantu   \n",
       "2   16/07/2020                       Crio   \n",
       "3   14/07/2020                    goDutch   \n",
       "4   13/07/2020                   Mystifly   \n",
       "5   09/07/2020               JetSynthesys   \n",
       "6   10/07/2020                   gigIndia   \n",
       "7   15/07/2020                  PumPumPum   \n",
       "8   14/07/2020                       FLYX   \n",
       "9   13/07/2020  Open Appliances Pvt. Ltd.   \n",
       "10  15/08/2020                     Practo   \n",
       "11  13/08/2020                    Medlife   \n",
       "12  13/08/2020                  HungerBox   \n",
       "13  04/08/2020                      Dunzo   \n",
       "14  11/08/2020                   Terra.do   \n",
       "15  12/08/2020                  Classplus   \n",
       "16  14/08/2020                       Niyo   \n",
       "17  10/08/2020                  ZestMoney   \n",
       "18  07/08/2020                FreshToHome   \n",
       "19  13/08/2020                    Eduvanz   \n",
       "20  08/09/2020                     Byju’s   \n",
       "21  12/09/2020                  mCaffeine   \n",
       "22  09/09/2020                     Qshala   \n",
       "23  02/09/2020                      Winzo   \n",
       "24  09/09/2020                Hippo Video   \n",
       "25  07/09/2020                    Melorra   \n",
       "26  07/09/2020                        1mg   \n",
       "27  31/08/2020                      mfine   \n",
       "28  31/08/2020                       Apna   \n",
       "29  03/09/2020                    Railofy   \n",
       "\n",
       "                         Industry/Vertical  \\\n",
       "0                               E-commerce   \n",
       "1                                  EduTech   \n",
       "2                                  EduTech   \n",
       "3                                  FinTech   \n",
       "4                      Airfare Marketplace   \n",
       "5                 Gaming and Entertainment   \n",
       "6                              Marketplace   \n",
       "7                        Automotive Rental   \n",
       "8                               OTT Player   \n",
       "9                   Information Technology   \n",
       "10                              HealthTech   \n",
       "11                              E-commerce   \n",
       "12                                FoodTech   \n",
       "13                   Hyper-local Logistics   \n",
       "14                                 EduTech   \n",
       "15                                 EduTech   \n",
       "16                                 FinTech   \n",
       "17                                 FinTech   \n",
       "18                              E-commerce   \n",
       "19                                 FinTech   \n",
       "20                                 EduTech   \n",
       "21                           Personal Care   \n",
       "22                                 EduTech   \n",
       "23                           Online Gaming   \n",
       "24  Video Customer Experience(CX) Platform   \n",
       "25                              E-commerce   \n",
       "26                              E-commerce   \n",
       "27                              HealthTech   \n",
       "28                         Human Resources   \n",
       "29                          Transportation   \n",
       "\n",
       "                                         Sub-Vertical  \\\n",
       "0                                          E-commerce   \n",
       "1                                     Online Tutoring   \n",
       "2                    Learning Platform for Developers   \n",
       "3                                      Group Payments   \n",
       "4   Ticketing, Airline Retailing, and Post-Ticketi...   \n",
       "5                            Gaming and Entertainment   \n",
       "6                           Crowd Sourcing, Freelance   \n",
       "7                           Used Car-leasing platform   \n",
       "8                            Streaming Social Network   \n",
       "9               Internet-of-Things Security Solutions   \n",
       "10                           Health care and Wellness   \n",
       "11                                    Online Pharmacy   \n",
       "12                       Online Food Delivery Service   \n",
       "13                           Online Delivery Services   \n",
       "14                  Online Climate School, E-learning   \n",
       "15                        E-learning, Online Tutoring   \n",
       "16                                 Financial Services   \n",
       "17                                 Financial Services   \n",
       "18                                      Food Delivery   \n",
       "19                                 Financial Services   \n",
       "20                                    Online Tutoring   \n",
       "21                                Skincare & Haircare   \n",
       "22                 Online Curiosity Platform for Kids   \n",
       "23                                      Online Gaming   \n",
       "24             Video Customer Experience(CX) Platform   \n",
       "25                               Online Jewelry Store   \n",
       "26                                    Online Pharmacy   \n",
       "27                      On-Demand Healthcare Services   \n",
       "28                               Recruitment Platform   \n",
       "29                       WL & RAC protection platform   \n",
       "\n",
       "                                          City  \\\n",
       "0                                    Bangalore   \n",
       "1                                    Bangalore   \n",
       "2                                    Bangalore   \n",
       "3                                       Mumbai   \n",
       "4                      Singapore and Bangalore   \n",
       "5                                         Pune   \n",
       "6                                         Pune   \n",
       "7                                      Gurgaon   \n",
       "8                           New York and Delhi   \n",
       "9                                    Bangalore   \n",
       "10                                   Bangalore   \n",
       "11                                   Bangalore   \n",
       "12                                   Bangalore   \n",
       "13                                   Bangalore   \n",
       "14                       Stanford, California,   \n",
       "15                                       Noida   \n",
       "16                                   Bangalore   \n",
       "17                                   Bangalore   \n",
       "18                                   Bangalore   \n",
       "19                                      Mumbai   \n",
       "20                                   Bangalore   \n",
       "21                                      Mumbai   \n",
       "22                                   Bangalore   \n",
       "23                                   New Delhi   \n",
       "24  Newark, Delaware, United States of Amercia   \n",
       "25                                   Bangalore   \n",
       "26                                     Gurgaon   \n",
       "27                                   Bangalore   \n",
       "28                                   Bangalore   \n",
       "29                                      Mumbai   \n",
       "\n",
       "                                             Investor         Investment Type  \\\n",
       "0                                         Walmart Inc                     M&A   \n",
       "1                                   Coatue Management                Series D   \n",
       "2                                         021 Capital            pre-Series A   \n",
       "3   Matrix India,Y Combinator, Global Founders Cap...                    Seed   \n",
       "4                                    Recruit Co. Ltd.            pre-Series B   \n",
       "5            Adar Poonawalla and Kris Gopalakrishnan.  Venture-Series Unknown   \n",
       "6        Incubate Fund India and Beyond Next Ventures            pre-Series A   \n",
       "7                            Early Adapters Syndicate                    Seed   \n",
       "8               Raj Mishra, founder of AIT Global Inc                pre-Seed   \n",
       "9                              Unicorn India Ventures  Venture-Series Unknown   \n",
       "10                                        A1A Company                Series F   \n",
       "11         Prasid Uno Family Trust and SC Credit Fund                           \n",
       "12  One97, Sabre Partners Trust, Pratithi Investme...               Series D1   \n",
       "13                                   Existing Backers             In Progress   \n",
       "14  Stanford Angels and Entrepreneurs (India), BEE...                    Seed   \n",
       "15                                        Falcon Edge             In Progress   \n",
       "16                                Niyo Solutions Inc.                           \n",
       "17                            Primrose Hills Ventures                           \n",
       "18                                     Ascent Capital                 Venture   \n",
       "19                              Sequoia India, Unitus                Series A   \n",
       "20  Silver Lake, Tiger Global, General Atlantic an...          Private Equity   \n",
       "21  Amicus Capital Private Equity I LLP, Amicus Ca...                Series B   \n",
       "22                                 Rainmatter Capital                   Angel   \n",
       "23  Kalaari Capital Partners, IndigoEdge Managemen...                Series B   \n",
       "24  Alpha Wave Incubation, Exfinity Venture Partne...                Series A   \n",
       "25                         Shadow Holdings, Lightbox.          Debt Financing   \n",
       "26         Gaja Capital, Tata Capital, Partners Group             In Progress   \n",
       "27                                   Caretech Pte Inc                Series B   \n",
       "28         Lightspeed India and Sequoia Capital India                Series A   \n",
       "29                                  Chiratae Ventures                    Seed   \n",
       "\n",
       "             Amount  \n",
       "0     1,200,000,000  \n",
       "1       100,000,000  \n",
       "2           934,160  \n",
       "3         1,700,000  \n",
       "4         3,300,000  \n",
       "5           400,000  \n",
       "6           974,200  \n",
       "7           292,800  \n",
       "8           200,000  \n",
       "9           500,000  \n",
       "10       32,000,000  \n",
       "11       23,000,000  \n",
       "12        1,560,000  \n",
       "13       30,000,000  \n",
       "14        1,400,000  \n",
       "15  upto 15,000,000  \n",
       "16        6,000,000  \n",
       "17       10,670,000  \n",
       "18       16,200,000  \n",
       "19        5,000,000  \n",
       "20      500,000,000  \n",
       "21        3,000,000  \n",
       "22          370,000  \n",
       "23       15,500,000  \n",
       "24        4,500,000  \n",
       "25   upto 8,900,000  \n",
       "26      100,000,000  \n",
       "27        5,400,000  \n",
       "28        8,000,000  \n",
       "29          950,000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Funding=pd.DataFrame({'Date':Date,'Startup Company':Startup,'Industry/Vertical':Industry,'Sub-Vertical':Sub_vertical,'City':City,\n",
    "                        'Investor':Investor,'Investment Type':Investment_type,'Amount':Amount})\n",
    "print('\\033[1m'+'Funding deals in second quarter (i.e. July 20 –September 20) :'+'\\033[0m')\n",
    "Funding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in chrome browser\n",
    "url='https://www.digit.in'\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on top 10 option button in menu bar\n",
    "driver.find_element_by_xpath('//div[@class=\"menu\"]/ul/li[4]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Clicking on Laptop under table\n",
    "driver.find_element_by_xpath('//div[@class=\"categoty_list\"]/button[2]').click()\n",
    "\n",
    "# Opening Best gaming laptops link\n",
    "Gaming_lappy=driver.find_element_by_xpath('//div[@id=\"laptops\"]/div[3]/a').get_attribute('href')\n",
    "driver.get(Gaming_lappy)\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Empty list for scraping data\n",
    "Laptop_model =[]\n",
    "OS =[]\n",
    "Display = []\n",
    "Processor =[]\n",
    "Memory =[]\n",
    "Weight =[]\n",
    "Dimension =[]\n",
    "Graphics_processor =[]\n",
    "Price =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Laptop model via Xpath\n",
    "for i in range(0,11):\n",
    "    laptop_model=driver.find_elements_by_xpath('//*[@id=\"toptenIdevent{}\"]/a/h3'.format(i))\n",
    "    for j in laptop_model:\n",
    "       Laptop_model.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting OS on Laptop model via Xpath\n",
    "os=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[3]/td[3]')\n",
    "for j in os:\n",
    "    OS.append(j.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Display vertical via Xpath\n",
    "display=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[4]/td[3]')\n",
    "for j in display:\n",
    "    Display.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Processor via xpath\n",
    "processor=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[5]/td[3]')\n",
    "for j in processor:\n",
    "    Processor.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Memory via xpath\n",
    "memory=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[6]/td[3]')\n",
    "for j in memory:\n",
    "    Memory.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Laptop Weight via xpath\n",
    "weight=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[7]/td[3]')\n",
    "for j in weight:\n",
    "    Weight.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Dimension via xpath\n",
    "dimension=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[8]/td[3]')\n",
    "for j in dimension:\n",
    "    Dimension.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Graphics Processor type via xpath\n",
    "graphics_processor=driver.find_elements_by_xpath('//div[@class=\"Spcs-details\"]/table/tbody/tr[9]/td[3]')\n",
    "for j in graphics_processor:\n",
    "    Graphics_processor.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Laptop Price type via xpath\n",
    "price=driver.find_elements_by_xpath('//table[@id=\"summtable\"]//tr//td[3]')\n",
    "for j in price:\n",
    "    Price.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest Gaming Laptop :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>OS</th>\n",
       "      <th>Display</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Graphical processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACER NITRO 5 RYZEN 9 (2021)</td>\n",
       "      <td>₹ 129,990</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>1 TB HDD/16 GBGB DDR4</td>\n",
       "      <td>AMD Ryzen 9 Octa Core | 2.4 GHz</td>\n",
       "      <td>2.4</td>\n",
       "      <td>363.4 x 255 x 23.9</td>\n",
       "      <td>NVIDIA GeForce RTX 3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI STEALTH 15M 11TH GEN CORE I7-11375H (2021</td>\n",
       "      <td>₹ 134,990</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>Intel Core i7 11th Gen - 11375H | NA</td>\n",
       "      <td>1.7</td>\n",
       "      <td>358.3 x 248 x 16.15</td>\n",
       "      <td>NVIDIA GeForce RTX 3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ROG STRIX SCAR 15 RYZEN 9-5900HX (2021)</td>\n",
       "      <td>₹ 268,990</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>15.6\" (2560 x 1440)</td>\n",
       "      <td>2 TB SSD/32 GBGB DDR4</td>\n",
       "      <td>AMD Ryzen 9 Octa Core - 5900HX | 3.3 GHz</td>\n",
       "      <td>2.30</td>\n",
       "      <td>354 x 259 x 22.6</td>\n",
       "      <td>NVIDIA GeForce RTX 3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALIENWARE AREA 51M R2</td>\n",
       "      <td>₹ 342,989</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>17.3\" (1920 x 1080)</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>10th Gen Intel® Core™ i7-10700 | 2.90 GHz</td>\n",
       "      <td>4.1</td>\n",
       "      <td>27.65 x 402.6 x 319.14</td>\n",
       "      <td>Intel® UHD Graphics 630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALIENWARE M15 R3</td>\n",
       "      <td>₹ 319,990</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (3840 x 2160)</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>10th Gen Intel® Core™ i9-10980HK | NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG STRIX SCAR 15</td>\n",
       "      <td>₹ 215,990</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>AMD Ryzen™ 9 5900HX | 3.3 GHz</td>\n",
       "      <td>2.30</td>\n",
       "      <td>35.4 x 25.9 x 2.26</td>\n",
       "      <td>NVIDIA® GeForce RTX™ 3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG ZEPHYRUS G14</td>\n",
       "      <td>₹ 164,990</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>14\" (1920 x 1080)</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>AMD 3rd Gen Ryzen 9 | 3.3 GHz</td>\n",
       "      <td>1.65</td>\n",
       "      <td>32.5 x 22.1 x 1.8</td>\n",
       "      <td>NVIDIA GeForce RTX 2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LENOVO LEGION 5I</td>\n",
       "      <td>₹ 76,988</td>\n",
       "      <td>Windows 10 Pro</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>1 TB SSD/16 GBGB DDR4</td>\n",
       "      <td>10th Gen Intel® Core™ i5-10300H | 2.50 GHz</td>\n",
       "      <td>2.3</td>\n",
       "      <td>363.06 x 259.61 x 23.57</td>\n",
       "      <td>NVIDIA® GeForce® GTX 1650 4GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ROG ZEPHYRUS DUO 15</td>\n",
       "      <td>₹ 185,000</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>15.6\" (3840 x 1100)</td>\n",
       "      <td>512 GB SSD/4 GBGB DDR4</td>\n",
       "      <td>Intel Core i7 10th Gen 10875H | NA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>268.30 x 360.00 x 20.90</td>\n",
       "      <td>NVIDIA GeForce RTX 2070 Max-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACER ASPIRE 7 GAMING</td>\n",
       "      <td>₹ 62,968</td>\n",
       "      <td>Windows 10 Home</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>512 GB SSD/8 GBGB DDR4</td>\n",
       "      <td>AMD Ryzen™ 5-5500U hexa-core | NA</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.29 x 36.3 x 25.4</td>\n",
       "      <td>NVIDIA® GeForce® GTX 1650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Laptop Model      Price               OS  \\\n",
       "0                    ACER NITRO 5 RYZEN 9 (2021)  ₹ 129,990       Windows 10   \n",
       "1  MSI STEALTH 15M 11TH GEN CORE I7-11375H (2021  ₹ 134,990       Windows 10   \n",
       "2   ASUS ROG STRIX SCAR 15 RYZEN 9-5900HX (2021)  ₹ 268,990       Windows 10   \n",
       "3                          ALIENWARE AREA 51M R2  ₹ 342,989  Windows 10 Home   \n",
       "4                               ALIENWARE M15 R3  ₹ 319,990  Windows 10 Home   \n",
       "5                         ASUS ROG STRIX SCAR 15  ₹ 215,990  Windows 10 Home   \n",
       "6                          ASUS ROG ZEPHYRUS G14  ₹ 164,990  Windows 10 Home   \n",
       "7                               LENOVO LEGION 5I   ₹ 76,988   Windows 10 Pro   \n",
       "8                       ASUS ROG ZEPHYRUS DUO 15  ₹ 185,000       Windows 10   \n",
       "9                           ACER ASPIRE 7 GAMING   ₹ 62,968  Windows 10 Home   \n",
       "\n",
       "               Display                  Memory  \\\n",
       "0  15.6\" (1920 x 1080)   1 TB HDD/16 GBGB DDR4   \n",
       "1  15.6\" (1920 x 1080)   1 TB SSD/16 GBGB DDR4   \n",
       "2  15.6\" (2560 x 1440)   2 TB SSD/32 GBGB DDR4   \n",
       "3  17.3\" (1920 x 1080)   1 TB SSD/16 GBGB DDR4   \n",
       "4  15.6\" (3840 x 2160)   1 TB SSD/16 GBGB DDR4   \n",
       "5  15.6\" (1920 x 1080)   1 TB SSD/16 GBGB DDR4   \n",
       "6    14\" (1920 x 1080)   1 TB SSD/16 GBGB DDR4   \n",
       "7  15.6\" (1920 x 1080)   1 TB SSD/16 GBGB DDR4   \n",
       "8  15.6\" (3840 x 1100)  512 GB SSD/4 GBGB DDR4   \n",
       "9  15.6\" (1920 x 1080)  512 GB SSD/8 GBGB DDR4   \n",
       "\n",
       "                                    Processor Weight                Dimension  \\\n",
       "0             AMD Ryzen 9 Octa Core | 2.4 GHz    2.4       363.4 x 255 x 23.9   \n",
       "1        Intel Core i7 11th Gen - 11375H | NA    1.7      358.3 x 248 x 16.15   \n",
       "2    AMD Ryzen 9 Octa Core - 5900HX | 3.3 GHz   2.30         354 x 259 x 22.6   \n",
       "3   10th Gen Intel® Core™ i7-10700 | 2.90 GHz    4.1   27.65 x 402.6 x 319.14   \n",
       "4       10th Gen Intel® Core™ i9-10980HK | NA     NA                       NA   \n",
       "5               AMD Ryzen™ 9 5900HX | 3.3 GHz   2.30       35.4 x 25.9 x 2.26   \n",
       "6               AMD 3rd Gen Ryzen 9 | 3.3 GHz   1.65        32.5 x 22.1 x 1.8   \n",
       "7  10th Gen Intel® Core™ i5-10300H | 2.50 GHz    2.3  363.06 x 259.61 x 23.57   \n",
       "8          Intel Core i7 10th Gen 10875H | NA    2.4  268.30 x 360.00 x 20.90   \n",
       "9           AMD Ryzen™ 5-5500U hexa-core | NA   2.15       2.29 x 36.3 x 25.4   \n",
       "\n",
       "             Graphical processor  \n",
       "0        NVIDIA GeForce RTX 3070  \n",
       "1        NVIDIA GeForce RTX 3060  \n",
       "2        NVIDIA GeForce RTX 3080  \n",
       "3        Intel® UHD Graphics 630  \n",
       "4                             NA  \n",
       "5      NVIDIA® GeForce RTX™ 3070  \n",
       "6        NVIDIA GeForce RTX 2060  \n",
       "7  NVIDIA® GeForce® GTX 1650 4GB  \n",
       "8  NVIDIA GeForce RTX 2070 Max-Q  \n",
       "9      NVIDIA® GeForce® GTX 1650  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make data frame\n",
    "Gaming_Laptops=pd.DataFrame({\"Laptop Model\":Laptop_model,\"Price\":Price, \"OS\":OS,\"Display\":Display,\"Memory\":Memory,\"Processor\":Processor,\n",
    "                 \"Weight\":Weight,\"Dimension\":Dimension,\"Graphical processor\":Graphics_processor})\n",
    "print('\\033[1m'+'Best Gaming Laptop :'+'\\033[0m')\n",
    "Gaming_Laptops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in chrome browser\n",
    "url=\"https://www.forbes.com\"\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on explore button to expand menu\n",
    "driver.find_element_by_xpath('//button[@class=\"icon--hamburger\"]').click()\n",
    "\n",
    "# Clicking on Billionaire category\n",
    "driver.find_element_by_xpath('//ul[@class=\"header__channels\"]/li[1]').click()\n",
    "\n",
    "# Clicking on world billionaire tab\n",
    "driver.find_element_by_xpath('//ul[@class=\"header__channels\"]/li[1]/div[2]/ul/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to scrap data\n",
    "Rank =[]\n",
    "Name=[]\n",
    "Net_worth=[]\n",
    "Age=[]\n",
    "Citizenship=[]\n",
    "Source=[]\n",
    "Industry=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank No\n",
    "rank=driver.find_elements_by_xpath('//div[@class=\"rank\"]')\n",
    "for i in rank:\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extacting name\n",
    "name=driver.find_elements_by_xpath('//div[@class=\"personName\"]/div')\n",
    "for i in name:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Net worth\n",
    "net=driver.find_elements_by_xpath('//div[@class=\"netWorth\"]/div')\n",
    "for i in net:\n",
    "    Net_worth.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Age\n",
    "age=driver.find_elements_by_xpath('//div[@class=\"age\"]/div')\n",
    "for i in age:\n",
    "    Age.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Extracting Citizenship\n",
    "citizen=driver.find_elements_by_xpath('//div[@class=\"countryOfCitizenship\"]')\n",
    "for i in citizen:\n",
    "    Citizenship.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Source\n",
    "try:\n",
    "    source=driver.find_elements_by_xpath('//div[@class=\"source-column\"]')\n",
    "    for i in source:\n",
    "        Source.append(i.text)\n",
    "except:\n",
    "    source=driver.find_elements_by_xpath('//*[@id=\"jeff-bezos\"]/div[6]/div/div[1]')\n",
    "    Source.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Industry\n",
    "industry=driver.find_elements_by_xpath(\"//div[@class='category']//div\")\n",
    "for i in industry:\n",
    "    Industry.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Forbes World Billionaires List Oct 2021 :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Net Worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$177 B</td>\n",
       "      <td>57</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$151 B</td>\n",
       "      <td>49</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$150 B</td>\n",
       "      <td>72</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$124 B</td>\n",
       "      <td>65</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>$97 B</td>\n",
       "      <td>36</td>\n",
       "      <td>United States</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195.</td>\n",
       "      <td>Harry Triguboff</td>\n",
       "      <td>$11.2 B</td>\n",
       "      <td>88</td>\n",
       "      <td>Australia</td>\n",
       "      <td>real estate</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197.</td>\n",
       "      <td>Leonid Fedun &amp; family</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>65</td>\n",
       "      <td>Russia</td>\n",
       "      <td>oil</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197.</td>\n",
       "      <td>Eyal Ofer</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>70</td>\n",
       "      <td>Israel</td>\n",
       "      <td>real estate, shipping</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>197.</td>\n",
       "      <td>Evan Spiegel</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>30</td>\n",
       "      <td>United States</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200.</td>\n",
       "      <td>Luis Carlos Sarmiento</td>\n",
       "      <td>$11 B</td>\n",
       "      <td>88</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>banking</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                      Name Net Worth Age    Citizenship  \\\n",
       "0      1.                Jeff Bezos    $177 B  57  United States   \n",
       "1      2.                 Elon Musk    $151 B  49  United States   \n",
       "2      3.  Bernard Arnault & family    $150 B  72         France   \n",
       "3      4.                Bill Gates    $124 B  65  United States   \n",
       "4      5.           Mark Zuckerberg     $97 B  36  United States   \n",
       "..    ...                       ...       ...  ..            ...   \n",
       "195  195.           Harry Triguboff   $11.2 B  88      Australia   \n",
       "196  197.     Leonid Fedun & family   $11.1 B  65         Russia   \n",
       "197  197.                 Eyal Ofer   $11.1 B  70         Israel   \n",
       "198  197.              Evan Spiegel   $11.1 B  30  United States   \n",
       "199  200.     Luis Carlos Sarmiento     $11 B  88       Colombia   \n",
       "\n",
       "                    Source               Industry  \n",
       "0                   Amazon             Technology  \n",
       "1            Tesla, SpaceX             Automotive  \n",
       "2                     LVMH       Fashion & Retail  \n",
       "3                Microsoft             Technology  \n",
       "4                 Facebook             Technology  \n",
       "..                     ...                    ...  \n",
       "195            real estate            Real Estate  \n",
       "196                    oil                 Energy  \n",
       "197  real estate, shipping            Diversified  \n",
       "198               Snapchat             Technology  \n",
       "199                banking  Finance & Investments  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "Forbes_list=pd.DataFrame({'Rank':Rank,'Name':Name,'Net Worth':Net_worth,'Age':Age,'Citizenship':Citizenship,\n",
    "                'Source':Source,'Industry':Industry})\n",
    "print('\\033[1m'+' Forbes World Billionaires List Oct 2021 :'+'\\033[0m')\n",
    "Forbes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in chrome browser\n",
    "url=\"https://www.youtube.com\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding search menu by xpath\n",
    "Search=driver.find_element_by_xpath('//input[@id=\"search\"]') \n",
    "# Feeding input video name by user to search menu through send keys\n",
    "Search.send_keys('Healing Ragas - Sitar Tabla - Brindavan Sarang - Classical Instrumental Fusion B.Sivaramakrishna Rao')\n",
    "# Finding Search button for clicking through xpath\n",
    "Search_button=driver.find_element_by_xpath('//button[@id=\"search-icon-legacy\"]/yt-icon')  \n",
    "# Clicking search button\n",
    "Search_button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on video\n",
    "link = driver.find_element_by_xpath(\"//yt-formatted-string[@class ='style-scope ytd-video-renderer']\")\n",
    "link.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolling window using ScrollBy method from 0 pixel to 15000 pixel\n",
    "driver.execute_script(\"window.scrollBy(0,1000000)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists to scrap data\n",
    "Comments = []\n",
    "Comment_posted_ago = []\n",
    "Timeline = []\n",
    "Likes = []\n",
    "No_of_Likes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591/591 [00:27<00:00, 21.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#extracting comment on video\n",
    "comment = driver.find_elements_by_id(\"content-text\")\n",
    "time.sleep(3)\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(comment):\n",
    "    if i.text is None:\n",
    "        Comments.append(\"--\")\n",
    "    else:\n",
    "        Comments.append(i.text)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:54<00:00, 22.03it/s]\n",
      "100%|██████████| 600/600 [00:00<00:00, 46180.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extracting time of commenting\n",
    "timeline = driver.find_elements_by_xpath(\"//a[contains(text(),'ago')]\")\n",
    "time.sleep(3)\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(timeline):\n",
    "    if i.text is None:\n",
    "        Timeline.append(\"-\")\n",
    "    else:\n",
    "        Timeline.append(i.text)\n",
    "for i in tqdm(range(0,len(Timeline),2)):\n",
    "    Comment_posted_ago.append(Timeline[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the comment likes\n",
    "like = driver.find_elements_by_xpath(\"//span[@class='style-scope ytd-comment-action-buttons-renderer']\")\n",
    "for i in like:\n",
    "    Likes.append(i.text)\n",
    "    \n",
    "for i in range(1,len(Likes),2):\n",
    "    No_of_Likes.append(Likes[i])\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591, 600, 600)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Comments),len(Comment_posted_ago),len(No_of_Likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Comment Posted Ago</th>\n",
       "      <th>No. of Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just close eyes. You will visualize the heaven...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indian spirituality has taught me so much also...</td>\n",
       "      <td>1 year ago</td>\n",
       "      <td>2.9K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm from East Asia China, and I also feel Indi...</td>\n",
       "      <td>1 year ago (edited)</td>\n",
       "      <td>2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know you're mature when you start preferri...</td>\n",
       "      <td>5 months ago</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm 6 months pregnant n listening to the music...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Beautiful soulful music..  but ads in between ...</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>I am from Bangladesh..\\nI love indian culture ...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Wow so Soulful 👏</td>\n",
       "      <td>1 year ago</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Really whenever someone feel hearted from his ...</td>\n",
       "      <td>1 year ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>We have proud on this art.</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comments   Comment Posted Ago  \\\n",
       "0    Just close eyes. You will visualize the heaven...        11 months ago   \n",
       "1    Indian spirituality has taught me so much also...           1 year ago   \n",
       "2    I'm from East Asia China, and I also feel Indi...  1 year ago (edited)   \n",
       "3    You know you're mature when you start preferri...         5 months ago   \n",
       "4    I'm 6 months pregnant n listening to the music...         7 months ago   \n",
       "..                                                 ...                  ...   \n",
       "495  Beautiful soulful music..  but ads in between ...          2 years ago   \n",
       "496  I am from Bangladesh..\\nI love indian culture ...         8 months ago   \n",
       "497                                   Wow so Soulful 👏           1 year ago   \n",
       "498  Really whenever someone feel hearted from his ...           1 year ago   \n",
       "499                         We have proud on this art.         4 months ago   \n",
       "\n",
       "    No. of Likes  \n",
       "0             1K  \n",
       "1           2.9K  \n",
       "2             2K  \n",
       "3            216  \n",
       "4            230  \n",
       "..           ...  \n",
       "495            3  \n",
       "496            5  \n",
       "497            2  \n",
       "498            1  \n",
       "499            1  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT=pd.DataFrame({})\n",
    "YT['Comments']=Comments[:500]\n",
    "YT['Comment Posted Ago']=Comment_posted_ago[:500]\n",
    "YT['No. of Likes']=No_of_Likes[:500]\n",
    "YT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to webdriver\n",
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening url in chrome browser\n",
    "url=\"https://www.hostelworld.com\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"page-footer-accomodation\"]/ul/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the location search bar\n",
    "Search = driver.find_element_by_xpath('//input[@id=\"home-search-keywords\"]')\n",
    "\n",
    "# Sending input London in search bar\n",
    "Search.send_keys(\"London\")\n",
    "time.sleep(1)\n",
    "\n",
    "#select london\n",
    "london = driver.find_element_by_xpath('//*[@id=\"top-search\"]/div/div[1]/div[2]/ul/li[2]')\n",
    "london.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# do click on search button\n",
    "Search_button = driver.find_element_by_xpath('//*[@id=\"top-search\"]/div/div[2]/button')\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find required data\n",
    "hostel_name = []\n",
    "distance = []\n",
    "pvt_prices = []\n",
    "dorms_price = []\n",
    "rating = []\n",
    "reviews = []\n",
    "over_all = []\n",
    "facilities = []\n",
    "description =[]\n",
    "product_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'pagination-item pagination-current' or @class='pagination-item']\"):\n",
    "    i.click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    #fetching hostel name\n",
    "    try:\n",
    "        name = driver.find_elements_by_xpath(\"//h2[@class='title title-6']\")\n",
    "        for i in name:\n",
    "            hostel_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        hostel_name.append('-')\n",
    "        \n",
    "    #fetching distance from city centre\n",
    "    \n",
    "    try:\n",
    "        dist = driver.find_elements_by_xpath(\"//div[@class='subtitle body-3']//a//span[1]\")\n",
    "        for i in dist:\n",
    "            distance.append(i.text.replace('Hostel - ',''))\n",
    "    except NoSuchElementException:\n",
    "        distance.append('-')\n",
    "        \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='prices-col']\"):\n",
    "    #fetch privates from price\n",
    "        try:\n",
    "            pvt_price = driver.find_element_by_xpath(\"//a[@class='prices']//div[1]//div\")\n",
    "            pvt_prices.append(pvt_price.text)\n",
    "        except NoSuchElementException:\n",
    "            pvt_prices.append('-')\n",
    "    #fetching dorms from price\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='prices-col']\"):\n",
    "        try:\n",
    "            dorms = driver.find_element_by_xpath(\"//a[@class='prices']//div[2]//div\")\n",
    "            dorms_price.append(dorms.text)\n",
    "        except NoSuchElementException:\n",
    "            dorms_price.append('-')\n",
    "    #fetching facilities\n",
    "    try:\n",
    "        fac1 = driver.find_elements_by_xpath(\"//div[@class='has-wifi']\")\n",
    "        fac2 = driver.find_elements_by_xpath(\"//div[@class='has-sanitation']\")\n",
    "        for i in fac1:\n",
    "            for j in fac2:\n",
    "                facilities.append(i.text +', '+ j.text )\n",
    "    except NoSuchElementException:\n",
    "        facilities.append('-')\n",
    "    #lets fetch url of each hostel\n",
    "    p_url = driver.find_elements_by_xpath(\"//div[@class='prices-col']//a[2]\")\n",
    "    for i in p_url:\n",
    "        product_url.append(i.get_attribute('href'))\n",
    "\n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    #lets click on show more button for description\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class='toggle-content']\").click()\n",
    "        time.sleep(5)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #fetching ratings\n",
    "    try:\n",
    "        rat = driver.find_element_by_xpath(\"//div[@class='score orange big' or @class='score gray big']\")\n",
    "        rating.append(rat.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append('-')\n",
    "    #fetching total reviews\n",
    "        \n",
    "    try:\n",
    "        rws = driver.find_element_by_xpath(\"//div[@class='reviews']\")\n",
    "        reviews.append(rws.text.replace('Total Reviews',''))\n",
    "    except NoSuchElementException:\n",
    "        reviews.append('-')\n",
    "    #fetch overall review\n",
    "    try:\n",
    "        overall_rw = driver.find_element_by_xpath(\"//div[@class='keyword']//span\")\n",
    "        over_all.append(overall_rw.text)\n",
    "    except NoSuchElementException:\n",
    "        over_all.append('-')\n",
    "    #fetch property description \n",
    "    try:\n",
    "        disc = driver.find_element_by_xpath(\"//div[@class='content']\")\n",
    "        description.append(disc.text)\n",
    "    except NoSuchElementException:\n",
    "        over_all.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Hostel Available in London :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hostel name</th>\n",
       "      <th>Distance from city centre</th>\n",
       "      <th>ratings</th>\n",
       "      <th>Total reviews</th>\n",
       "      <th>Overall review</th>\n",
       "      <th>Privates from price</th>\n",
       "      <th>Dorms from price</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Property Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Astor Hyde Park</td>\n",
       "      <td>4.3km from city centre</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11355</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>Rs21287</td>\n",
       "      <td>Rs1549</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "      <td>191 Queensgate, South Kensington, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>St Christopher's Village</td>\n",
       "      <td>1.8km from city centre</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10885</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>Rs21287</td>\n",
       "      <td>Rs1549</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "      <td>165 Borough High Street, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smart Camden Inn Hostel</td>\n",
       "      <td>4.4km from city centre</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2698</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>Rs21287</td>\n",
       "      <td>Rs1549</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "      <td>55/57 Bayham Street, Camden, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Finnish Church in London</td>\n",
       "      <td>4.5km from city centre</td>\n",
       "      <td>9.5</td>\n",
       "      <td>194</td>\n",
       "      <td>Superb</td>\n",
       "      <td>Rs21287</td>\n",
       "      <td>Rs1549</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "      <td>33 Albion Street, Rotherhithe, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No.8 Seven Sisters</td>\n",
       "      <td>9km from city centre</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3643</td>\n",
       "      <td>Good</td>\n",
       "      <td>Rs21287</td>\n",
       "      <td>Rs1549</td>\n",
       "      <td>Free WiFi, Follows Covid-19 sanitation guidance</td>\n",
       "      <td>618 Seven Sisters Rd, Seven Sisters, London, E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Hostel name Distance from city centre ratings  \\\n",
       "0               Astor Hyde Park    4.3km from city centre     8.9   \n",
       "1      St Christopher's Village    1.8km from city centre     8.3   \n",
       "2       Smart Camden Inn Hostel    4.4km from city centre     8.9   \n",
       "3  The Finnish Church in London    4.5km from city centre     9.5   \n",
       "4            No.8 Seven Sisters      9km from city centre     6.7   \n",
       "\n",
       "  Total reviews Overall review Privates from price Dorms from price  \\\n",
       "0        11355        Fabulous             Rs21287           Rs1549   \n",
       "1        10885        Fabulous             Rs21287           Rs1549   \n",
       "2         2698        Fabulous             Rs21287           Rs1549   \n",
       "3          194          Superb             Rs21287           Rs1549   \n",
       "4         3643            Good             Rs21287           Rs1549   \n",
       "\n",
       "                                        Facilities  \\\n",
       "0  Free WiFi, Follows Covid-19 sanitation guidance   \n",
       "1  Free WiFi, Follows Covid-19 sanitation guidance   \n",
       "2  Free WiFi, Follows Covid-19 sanitation guidance   \n",
       "3  Free WiFi, Follows Covid-19 sanitation guidance   \n",
       "4  Free WiFi, Follows Covid-19 sanitation guidance   \n",
       "\n",
       "                                Property Description  \n",
       "0  191 Queensgate, South Kensington, London, England  \n",
       "1           165 Borough High Street, London, England  \n",
       "2       55/57 Bayham Street, Camden, London, England  \n",
       "3     33 Albion Street, Rotherhithe, London, England  \n",
       "4  618 Seven Sisters Rd, Seven Sisters, London, E...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "data = list(zip(hostel_name,distance,rating,reviews,over_all,pvt_prices,dorms_price,facilities,description))       \n",
    "Hostel = pd.DataFrame(data, columns = [\"Hostel name\",\"Distance from city centre\",\"ratings\",\"Total reviews\",\"Overall review\",\"Privates from price\",\"Dorms from price\",\"Facilities\",\"Property Description\"])\n",
    "print('\\033[1m'+' Hostel Available in London :'+'\\033[0m')\n",
    "Hostel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
