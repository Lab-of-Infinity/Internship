{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWikipedia Main Page Header Tag\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia Main Page Header Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Navigation menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Personal tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Namespaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Variantsexpandedcollapsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Moreexpandedcollapsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Contribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Print/export</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>In other projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia Main Page Header Tag\n",
       "0                       Main Page\n",
       "1   From today's featured article\n",
       "2                Did you know ...\n",
       "3                     In the news\n",
       "4                     On this day\n",
       "5        Today's featured picture\n",
       "6        Other areas of Wikipedia\n",
       "7     Wikipedia's sister projects\n",
       "8             Wikipedia languages\n",
       "9                 Navigation menu\n",
       "10                 Personal tools\n",
       "11                     Namespaces\n",
       "12      Variantsexpandedcollapsed\n",
       "13                          Views\n",
       "14          Moreexpandedcollapsed\n",
       "15                         Search\n",
       "16                     Navigation\n",
       "17                     Contribute\n",
       "18                          Tools\n",
       "19                   Print/export\n",
       "20              In other projects\n",
       "21                      Languages"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wiki = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(wiki.text, 'html.parser')\n",
    "\n",
    "head_tag=soup.find_all(['h1','h2','h3'])\n",
    "Header =[]\n",
    "for i in head_tag:\n",
    "    Header.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "\n",
    "Wikipedia_Header=pd.DataFrame({})\n",
    "Wikipedia_Header['Wikipedia Main Page Header Tag']=Header\n",
    "print('\\033[1m'+'Wikipedia Main Page Header Tag'+'\\033[0m')\n",
    "Wikipedia_Header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of  release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIMDB’s Top rated 100 movies of all time\u001b[0m\n",
      "1 - The Shawshank Redemption (1994) - Starring: Frank Darabont (dir.), Tim Robbins, Morgan Freeman 9.220525437092023\n",
      "2 - The Godfather (1972) - Starring: Francis Ford Coppola (dir.), Marlon Brando, Al Pacino 9.147254693401418\n",
      "3 - The Godfather: Part II (1974) - Starring: Francis Ford Coppola (dir.), Al Pacino, Robert De Niro 8.980484762364446\n",
      "4 - The Dark Knight (2008) - Starring: Christopher Nolan (dir.), Christian Bale, Heath Ledger 8.973007013854483\n",
      "5 - 12 Angry Men (1957) - Starring: Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb 8.939052346008403\n",
      "6 - Schindler's List (1993) - Starring: Steven Spielberg (dir.), Liam Neeson, Ralph Fiennes 8.911126451636287\n",
      "7 - The Lord of the Rings: The Return of the King (2003) - Starring: Peter Jackson (dir.), Elijah Wood, Viggo Mortensen 8.888265690162909\n",
      "8 - Pulp Fiction (1994) - Starring: Quentin Tarantino (dir.), John Travolta, Uma Thurman 8.836093366296193\n",
      "9 - Il buono, il brutto, il cattivo (1966) - Starring: Sergio Leone (dir.), Clint Eastwood, Eli Wallach 8.786417616879934\n",
      "1 -  The Lord of the Rings: The Fellowship of the Ring (2001) - Starring: Peter Jackson (dir.), Elijah Wood, Ian McKellen 8.778483299588494\n",
      "11 - Fight Club (1999) - Starring: David Fincher (dir.), Brad Pitt, Edward Norton 8.752366727473314\n",
      "12 - Forrest Gump (1994) - Starring: Robert Zemeckis (dir.), Tom Hanks, Robin Wright 8.743875443879208\n",
      "13 - Inception (2010) - Starring: Christopher Nolan (dir.), Leonardo DiCaprio, Joseph Gordon-Levitt 8.714658217044231\n",
      "14 - The Lord of the Rings: The Two Towers (2002) - Starring: Peter Jackson (dir.), Elijah Wood, Ian McKellen 8.701984020346915\n",
      "15 - Star Wars: Episode V - The Empire Strikes Back (1980) - Starring: Irvin Kershner (dir.), Mark Hamill, Harrison Ford 8.694831695847846\n",
      "16 - The Matrix (1999) - Starring: Lana Wachowski (dir.), Keanu Reeves, Laurence Fishburne 8.645260663336758\n",
      "17 - Goodfellas (1990) - Starring: Martin Scorsese (dir.), Robert De Niro, Ray Liotta 8.643779197918887\n",
      "18 - One Flew Over the Cuckoo's Nest (1975) - Starring: Milos Forman (dir.), Jack Nicholson, Louise Fletcher 8.635175324924898\n",
      "19 - Shichinin no samurai (1954) - Starring: Akira Kurosawa (dir.), Toshirô Mifune, Takashi Shimura 8.609180583398652\n",
      "20 - Se7en (1995) - Starring: David Fincher (dir.), Morgan Freeman, Brad Pitt 8.587256533693381\n",
      "21 - The Silence of the Lambs (1991) - Starring: Jonathan Demme (dir.), Jodie Foster, Anthony Hopkins 8.57699853618905\n",
      "22 - Cidade de Deus (2002) - Starring: Fernando Meirelles (dir.), Alexandre Rodrigues, Leandro Firmino 8.576388110409992\n",
      "23 - La vita è bella (1997) - Starring: Roberto Benigni (dir.), Roberto Benigni, Nicoletta Braschi 8.574751661164576\n",
      "24 - It's a Wonderful Life (1946) - Starring: Frank Capra (dir.), James Stewart, Donna Reed 8.574164423773945\n",
      "25 - Star Wars (1977) - Starring: George Lucas (dir.), Mark Hamill, Harrison Ford 8.551744905348423\n",
      "26 - Saving Private Ryan (1998) - Starring: Steven Spielberg (dir.), Tom Hanks, Matt Damon 8.5498736912818\n",
      "27 - Interstellar (2014) - Starring: Christopher Nolan (dir.), Matthew McConaughey, Anne Hathaway 8.539047786013564\n",
      "28 - Sen to Chihiro no kamikakushi (2001) - Starring: Hayao Miyazaki (dir.), Daveigh Chase, Suzanne Pleshette 8.538394881071776\n",
      "29 - The Green Mile (1999) - Starring: Frank Darabont (dir.), Tom Hanks, Michael Clarke Duncan 8.535769723509029\n",
      "30 - Gisaengchung (2019) - Starring: Bong Joon Ho (dir.), Kang-ho Song, Sun-kyun Lee 8.527717705323646\n",
      "31 - Léon (1994) - Starring: Luc Besson (dir.), Jean Reno, Gary Oldman 8.499653062993588\n",
      "32 - Seppuku (1962) - Starring: Masaki Kobayashi (dir.), Tatsuya Nakadai, Akira Ishihama 8.495560979337155\n",
      "33 - The Pianist (2002) - Starring: Roman Polanski (dir.), Adrien Brody, Thomas Kretschmann 8.489382621624161\n",
      "34 - The Usual Suspects (1995) - Starring: Bryan Singer (dir.), Kevin Spacey, Gabriel Byrne 8.486459196879734\n",
      "35 - Terminator 2: Judgment Day (1991) - Starring: James Cameron (dir.), Arnold Schwarzenegger, Linda Hamilton 8.484589561348098\n",
      "36 - Back to the Future (1985) - Starring: Robert Zemeckis (dir.), Michael J. Fox, Christopher Lloyd 8.484276739380666\n",
      "37 - Psycho (1960) - Starring: Alfred Hitchcock (dir.), Anthony Perkins, Janet Leigh 8.482065551165478\n",
      "38 - The Lion King (1994) - Starring: Roger Allers (dir.), Matthew Broderick, Jeremy Irons 8.480908306905915\n",
      "39 - Modern Times (1936) - Starring: Charles Chaplin (dir.), Charles Chaplin, Paulette Goddard 8.480483341350816\n",
      "40 - American History X (1998) - Starring: Tony Kaye (dir.), Edward Norton, Edward Furlong 8.47377105092814\n",
      "41 - City Lights (1931) - Starring: Charles Chaplin (dir.), Charles Chaplin, Virginia Cherrill 8.471638424234733\n",
      "42 - Hotaru no haka (1988) - Starring: Isao Takahata (dir.), Tsutomu Tatsumi, Ayano Shiraishi 8.469989561141722\n",
      "43 - Whiplash (2014) - Starring: Damien Chazelle (dir.), Miles Teller, J.K. Simmons 8.468479761352203\n",
      "44 - Gladiator (2000) - Starring: Ridley Scott (dir.), Russell Crowe, Joaquin Phoenix 8.468162742526717\n",
      "45 - The Departed (2006) - Starring: Martin Scorsese (dir.), Leonardo DiCaprio, Matt Damon 8.466689439761597\n",
      "46 - The Intouchables (2011) - Starring: Olivier Nakache (dir.), François Cluzet, Omar Sy 8.459662685686508\n",
      "47 - The Prestige (2006) - Starring: Christopher Nolan (dir.), Christian Bale, Hugh Jackman 8.452911192669017\n",
      "48 - Casablanca (1942) - Starring: Michael Curtiz (dir.), Humphrey Bogart, Ingrid Bergman 8.449554507190916\n",
      "49 - Once Upon a Time in the West (1968) - Starring: Sergio Leone (dir.), Henry Fonda, Charles Bronson 8.447909439166875\n",
      "50 - Rear Window (1954) - Starring: Alfred Hitchcock (dir.), James Stewart, Grace Kelly 8.438867891811535\n",
      "51 - Nuovo Cinema Paradiso (1988) - Starring: Giuseppe Tornatore (dir.), Philippe Noiret, Enzo Cannavale 8.436195887628836\n",
      "52 - Alien (1979) - Starring: Ridley Scott (dir.), Sigourney Weaver, Tom Skerritt 8.422554130210312\n",
      "53 - Apocalypse Now (1979) - Starring: Francis Ford Coppola (dir.), Martin Sheen, Marlon Brando 8.417558519398339\n",
      "54 - Memento (2000) - Starring: Christopher Nolan (dir.), Guy Pearce, Carrie-Anne Moss 8.40942092273915\n",
      "55 - Raiders of the Lost Ark (1981) - Starring: Steven Spielberg (dir.), Harrison Ford, Karen Allen 8.406478833023833\n",
      "56 - The Great Dictator (1940) - Starring: Charles Chaplin (dir.), Charles Chaplin, Paulette Goddard 8.404805133879645\n",
      "57 - The Lives of Others (2006) - Starring: Florian Henckel von Donnersmarck (dir.), Ulrich Mühe, Martina Gedeck 8.39131459102549\n",
      "58 - Django Unchained (2012) - Starring: Quentin Tarantino (dir.), Jamie Foxx, Christoph Waltz 8.389652859216119\n",
      "59 - Paths of Glory (1957) - Starring: Stanley Kubrick (dir.), Kirk Douglas, Ralph Meeker 8.382964995198353\n",
      "60 - Sunset Blvd (1950) - Starring: Billy Wilder (dir.), William Holden, Gloria Swanson 8.377148055078317\n",
      "61 - WALL·E (2008) - Starring: Andrew Stanton (dir.), Ben Burtt, Elissa Knight 8.372915083472206\n",
      "62 - Avengers: Infinity War (2018) - Starring: Anthony Russo (dir.), Robert Downey Jr., Chris Hemsworth 8.365047592946443\n",
      "63 - The Shining (1980) - Starring: Stanley Kubrick (dir.), Jack Nicholson, Shelley Duvall 8.364604788612874\n",
      "64 - Witness for the Prosecution (1957) - Starring: Billy Wilder (dir.), Tyrone Power, Marlene Dietrich 8.363564160376004\n",
      "65 - Spider-Man: Into the Spider-Verse (2018) - Starring: Bob Persichetti (dir.), Shameik Moore, Jake Johnson 8.354239463544971\n",
      "66 - Dr Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) - Starring: Stanley Kubrick (dir.), Peter Sellers, George C. Scott 8.353154077519525\n",
      "67 - Joker (2019) - Starring: Todd Phillips (dir.), Joaquin Phoenix, Robert De Niro 8.348825749531162\n",
      "68 - Mononoke-hime (1997) - Starring: Hayao Miyazaki (dir.), Yôji Matsuda, Yuriko Ishida 8.344783803097313\n",
      "69 - Oldeuboi (2003) - Starring: Park Chan-Wook (dir.), Choi Min-sik, Yoo Ji-Tae 8.344268488932707\n",
      "70 - Kimi no na wa (2016) - Starring: Makoto Shinkai (dir.), Ryûnosuke Kamiki, Mone Kamishiraishi 8.326244428734695\n",
      "71 - Once Upon a Time in America (1984) - Starring: Sergio Leone (dir.), Robert De Niro, James Woods 8.322963432175529\n",
      "72 - The Dark Knight Rises (2012) - Starring: Christopher Nolan (dir.), Christian Bale, Tom Hardy 8.322563833034478\n",
      "73 - Aliens (1986) - Starring: James Cameron (dir.), Sigourney Weaver, Michael Biehn 8.321435369314422\n",
      "74 - Coco (2017) - Starring: Lee Unkrich (dir.), Anthony Gonzalez, Gael García Bernal 8.321369241818278\n",
      "75 - Capharnaüm (2018) - Starring: Nadine Labaki (dir.), Zain Al Rafeea, Yordanos Shiferaw 8.31021148469804\n",
      "76 - Avengers: Endgame (2019) - Starring: Anthony Russo (dir.), Robert Downey Jr., Chris Evans 8.308277068027571\n",
      "77 - Das Boot (1981) - Starring: Wolfgang Petersen (dir.), Jürgen Prochnow, Herbert Grönemeyer 8.307116018131758\n",
      "78 - Hamilton (2020) - Starring: Thomas Kail (dir.), Lin-Manuel Miranda, Phillipa Soo 8.306581156433783\n",
      "79 - Tengoku to jigoku (1963) - Starring: Akira Kurosawa (dir.), Toshirô Mifune, Yutaka Sada 8.304457936431291\n",
      "80 - American Beauty (1999) - Starring: Sam Mendes (dir.), Kevin Spacey, Annette Bening 8.298104433666518\n",
      "81 - Toy Story (1995) - Starring: John Lasseter (dir.), Tom Hanks, Tim Allen 8.296194657663758\n",
      "82 - 3 Idiots (2009) - Starring: Rajkumar Hirani (dir.), Aamir Khan, Madhavan 8.296010340229342\n",
      "83 - Amadeus (1984) - Starring: Milos Forman (dir.), F. Murray Abraham, Tom Hulce 8.29473780468429\n",
      "84 - Braveheart (1995) - Starring: Mel Gibson (dir.), Mel Gibson, Sophie Marceau 8.29419833442334\n",
      "85 - Inglourious Basterds (2009) - Starring: Quentin Tarantino (dir.), Brad Pitt, Diane Kruger 8.287686752059303\n",
      "86 - Good Will Hunting (1997) - Starring: Gus Van Sant (dir.), Robin Williams, Matt Damon 8.2807489732348\n",
      "87 - Star Wars: Episode VI - Return of the Jedi (1983) - Starring: Richard Marquand (dir.), Mark Hamill, Harrison Ford 8.274866001143065\n",
      "88 - 2001: A Space Odyssey (1968) - Starring: Stanley Kubrick (dir.), Keir Dullea, Gary Lockwood 8.273300784112948\n",
      "89 - Reservoir Dogs (1992) - Starring: Quentin Tarantino (dir.), Harvey Keitel, Tim Roth 8.2721193314144\n",
      "90 - M - Eine Stadt sucht einen Mörder (1931) - Starring: Fritz Lang (dir.), Peter Lorre, Ellen Widmann 8.271024797442745\n",
      "91 - Taare Zameen Par (2007) - Starring: Aamir Khan (dir.), Darsheel Safary, Aamir Khan 8.27091515844329\n",
      "92 - Vertigo (1958) - Starring: Alfred Hitchcock (dir.), James Stewart, Kim Novak 8.269166198178242\n",
      "93 - Citizen Kane (1941) - Starring: Orson Welles (dir.), Orson Welles, Joseph Cotten 8.267664695394211\n",
      "94 - Idi i smotri (1985) - Starring: Elem Klimov (dir.), Aleksey Kravchenko, Olga Mironova 8.266423034239654\n",
      "95 - Jagten (2012) - Starring: Thomas Vinterberg (dir.), Mads Mikkelsen, Thomas Bo Larsen 8.264664620383403\n",
      "96 - Requiem for a Dream (2000) - Starring: Darren Aronofsky (dir.), Ellen Burstyn, Jared Leto 8.261462792692205\n",
      "97 - Dune (2021) - Starring: Denis Villeneuve (dir.), Timothée Chalamet, Rebecca Ferguson 8.261415291772611\n",
      "98 - Singin' in the Rain (1952) - Starring: Stanley Donen (dir.), Gene Kelly, Donald O'Connor 8.25892682450876\n",
      "99 - North by Northwest (1959) - Starring: Alfred Hitchcock (dir.), Cary Grant, Eva Marie Saint 8.257844733908808\n",
      "10 -  Eternal Sunshine of the Spotless Mind (2004) - Starring: Michel Gondry (dir.), Jim Carrey, Kate Winslet 8.256125092454068\n",
      "101 - Ikiru (1952) - Starring: Akira Kurosawa (dir.), Takashi Shimura, Nobuo Kaneko 8.254753646851377\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "\n",
    "ratings = [b.attrs.get('data-value')\n",
    "\t\tfor b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "votes = [b.attrs.get('data-value')\n",
    "\t\tfor b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "list = []\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, 101):\n",
    "\t\n",
    "\t# Separating movie into: 'place',\n",
    "\t# 'title', 'year'\n",
    "\tmovie_string = movies[index].get_text()\n",
    "\tmovie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "\tmovie_title = movie[len(str(index))+1:-7]\n",
    "\tyear = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "\tplace = movie[:len(str(index))-(len(movie))]\n",
    "\tdata = {\"movie_title\": movie_title,\n",
    "\t\t\t\"year\": year,\n",
    "\t\t\t\"place\": place,\n",
    "\t\t\t\"star_cast\": crew[index],\n",
    "\t\t\t\"rating\": ratings[index],\n",
    "\t\t\t\"vote\": votes[index],\n",
    "\t\t\t\"link\": links[index]}\n",
    "\tlist.append(data)\n",
    "print('\\033[1m'+'IMDB’s Top rated 100 movies of all time'+'\\033[0m')\n",
    "# printing movie details with its rating.\n",
    "for movie in list:\n",
    "\tprint(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n",
    "\t\t') -', 'Starring:', movie['star_cast'], movie['rating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIMDB’s Top rated 100 Indian movies\u001b[0m\n",
      "1 - Nayakan (1987) - Starring: Mani Ratnam (dir.), Kamal Haasan, Saranya Ponvannan 8.494437884655886\n",
      "2 - Anbe Sivam (2003) - Starring: Sundar C. (dir.), Kamal Haasan, Madhavan 8.482870128127127\n",
      "3 - Pariyerum Perumal (2018) - Starring: Mari Selvaraj (dir.), Kathir, Anandhi 8.480358563778505\n",
      "4 - C/o Kancharapalem (2018) - Starring: Venkatesh Maha (dir.), Radha Bessy, Subba Rao Vepada 8.469823307101493\n",
      "5 - Golmaal (1979) - Starring: Hrishikesh Mukherjee (dir.), Amol Palekar, Bindiya Goswami 8.466881052035701\n",
      "6 - Manichitrathazhu (1993) - Starring: Fazil (dir.), Mohanlal, Shobana 8.46121580634493\n",
      "7 - Kireedam (1989) - Starring: Sibi Malayil (dir.), Mohanlal, Thilakan 8.460045191053817\n",
      "8 - Apur Sansar (1959) - Starring: Satyajit Ray (dir.), Soumitra Chatterjee, Sharmila Tagore 8.456428942777157\n",
      "9 - Natsamrat (2016) - Starring: Mahesh Manjrekar (dir.), Nana Patekar, Medha Manjrekar 8.436250582270226\n",
      "1 -  96 (2018) - Starring: C. Prem Kumar (dir.), Vijay Sethupathi, Adithya Bhaskar 8.42879466436595\n",
      "11 - Pather Panchali (1955) - Starring: Satyajit Ray (dir.), Kanu Bannerjee, Karuna Bannerjee 8.416875283077873\n",
      "12 - Kumbalangi Nights (2019) - Starring: Madhu C. Narayanan (dir.), Shane Nigam, Soubin Shahir 8.414832915227402\n",
      "13 - Thevar Magan (1992) - Starring: Bharathan (dir.), Kamal Haasan, Shivaji Ganesan 8.414316955831017\n",
      "14 - Black Friday (2004) - Starring: Anurag Kashyap (dir.), Kay Kay Menon, Pawan Malhotra 8.411089844644913\n",
      "15 - Soorarai Pottru (2020) - Starring: Sudha Kongara (dir.), Suriya, Paresh Rawal 8.363721291714395\n",
      "16 - Visaaranai (2015) - Starring: Vetrimaaran (dir.), Dinesh, Samuthirakani 8.360798667446836\n",
      "17 - 3 Idiots (2009) - Starring: Rajkumar Hirani (dir.), Aamir Khan, Madhavan 8.351022924955776\n",
      "18 - Jersey (2019) - Starring: Gowtam Tinnanuri (dir.), Nani, Shraddha Srinath 8.341773405829906\n",
      "19 - #Home (2021) - Starring: Rojin Thomas (dir.), Indrans, Sreenath Bhasi 8.340753277885254\n",
      "20 - Taare Zameen Par (2007) - Starring: Aamir Khan (dir.), Darsheel Safary, Aamir Khan 8.329354099311065\n",
      "21 - Drishyam 2 (2021) - Starring: Jeethu Joseph (dir.), Mohanlal, Meena 8.322762617345754\n",
      "22 - Asuran (2019) - Starring: Vetrimaaran (dir.), Dhanush, Manju Warrier 8.31937745337357\n",
      "23 - Thalapathi (1991) - Starring: Mani Ratnam (dir.), Rajinikanth, Mammootty 8.313656510774727\n",
      "24 - Sarpatta Parambarai (2021) - Starring: Pa. Ranjith (dir.), Arya, Pasupathy 8.308089565183042\n",
      "25 - Kaithi (2019) - Starring: Lokesh Kanagaraj (dir.), Karthi, Narain 8.307399900233968\n",
      "26 - Dangal (2016) - Starring: Nitesh Tiwari (dir.), Aamir Khan, Sakshi Tanwar 8.29858776459647\n",
      "27 - Devasuram (1993) - Starring: I.V. Sasi (dir.), Mohanlal, Revathi 8.292534143893775\n",
      "28 - Aparajito (1956) - Starring: Satyajit Ray (dir.), Pinaki Sengupta, Smaran Ghosal 8.279912888984638\n",
      "29 - Jaane Bhi Do Yaaro (1983) - Starring: Kundan Shah (dir.), Naseeruddin Shah, Ravi Baswani 8.275431966835967\n",
      "30 - Ratsasan (2018) - Starring: Ram Kumar (dir.), Vishnu Vishal, Amala Paul 8.272841404984122\n",
      "31 - Pyaasa (1957) - Starring: Guru Dutt (dir.), Guru Dutt, Waheeda Rehman 8.271920935462541\n",
      "32 - Vada Chennai (2018) - Starring: Vetrimaaran (dir.), Dhanush, Ameer Sultan 8.267704217154396\n",
      "33 - Peranbu (2018) - Starring: Ram (dir.), Mammootty, Sadhana 8.267483806203595\n",
      "34 - Guide (1965) - Starring: Vijay Anand (dir.), Dev Anand, Waheeda Rehman 8.261145499108942\n",
      "35 - Thani Oruvan (2015) - Starring: Mohan Raja (dir.), Jayam Ravi, Arvind Swamy 8.255883564578749\n",
      "36 - Kannathil Muthamittal (2002) - Starring: Mani Ratnam (dir.), Madhavan, Simran 8.244381160524828\n",
      "37 - Spadikam (1995) - Starring: Bhadran (dir.), Mohanlal, Thilakan 8.239862356674003\n",
      "38 - Agent Sai Srinivasa Athreya (2019) - Starring: Swaroop Rsj (dir.), Naveen Polishetty, Shruti Sharma 8.239479194276695\n",
      "39 - Iruvar (1997) - Starring: Mani Ratnam (dir.), Mohanlal, Prakash Raj 8.238753578485474\n",
      "40 - Chupke Chupke (1975) - Starring: Hrishikesh Mukherjee (dir.), Dharmendra, Sharmila Tagore 8.238745706041353\n",
      "41 - Super Deluxe (2019) - Starring: Thiagarajan Kumararaja (dir.), Vijay Sethupathi, Samantha Akkineni 8.231400892639055\n",
      "42 - Mahanati (2018) - Starring: Nag Ashwin (dir.), Keerthy Suresh, Dulquer Salmaan 8.225384058634084\n",
      "43 - Aruvi (2016) - Starring: Arun Prabhu Purushothaman (dir.), Aditi Balan, Padmashri Mohammad Ali 8.213813131149854\n",
      "44 - Drishyam (2013) - Starring: Jeethu Joseph (dir.), Mohanlal, Meena 8.21096298388068\n",
      "45 - Khosla Ka Ghosla! (2006) - Starring: Dibakar Banerjee (dir.), Anupam Kher, Boman Irani 8.207577675607636\n",
      "46 - Pudhu Pettai (2006) - Starring: K. Selvaraghavan (dir.), Dhanush, Sneha 8.205771879728609\n",
      "47 - Tumbbad (2018) - Starring: Rahi Anil Barve (dir.), Sohum Shah, Jyoti Malshe 8.197233518223761\n",
      "48 - Vikram Vedha (2017) - Starring: Gayatri (dir.), Madhavan, Vijay Sethupathi 8.196158009606604\n",
      "49 - Anniyan (2005) - Starring: S. Shankar (dir.), Vikram, Sada 8.186553757213094\n",
      "50 - Premam (2015) - Starring: Alphonse Puthren (dir.), Nivin Pauly, Sai Pallavi 8.186445206079188\n",
      "51 - Mudhalvan (1999) - Starring: S. Shankar (dir.), Arjun Sarja, Manisha Koirala 8.178109448448392\n",
      "52 - Kaakkaa Muttai (2014) - Starring: M. Manikandan (dir.), Ramesh, J. Vignesh 8.177777985508682\n",
      "53 - Bangalore Days (2014) - Starring: Anjali Menon (dir.), Nazriya Nazim, Nivin Pauly 8.177037537603336\n",
      "54 - Satya (1998) - Starring: Ram Gopal Varma (dir.), J.D. Chakravarthi, Manoj Bajpayee 8.171726943935996\n",
      "55 - Angoor (1982) - Starring: Gulzar (dir.), Sanjeev Kumar, Moushumi Chatterjee 8.169299107972728\n",
      "56 - Andhadhun (2018) - Starring: Sriram Raghavan (dir.), Ayushmann Khurrana, Tabu 8.168222739067314\n",
      "57 - Papanasam (2015) - Starring: Jeethu Joseph (dir.), Kamal Haasan, Gautami 8.16732548783505\n",
      "58 - Anand (1971) - Starring: Hrishikesh Mukherjee (dir.), Rajesh Khanna, Amitabh Bachchan 8.166433273640276\n",
      "59 - Soodhu Kavvum (2013) - Starring: Nalan Kumarasamy (dir.), Vijay Sethupathi, Sanchita Shetty 8.16353840587841\n",
      "60 - Dhuruvangal Pathinaaru (2016) - Starring: Karthick Naren (dir.), Rahman, Prakash Raghavan 8.162076483852463\n",
      "61 - Shahid (2012) - Starring: Hansal Mehta (dir.), Rajkummar Rao, Prabhleen Sandhu 8.158625033095\n",
      "62 - Gangs of Wasseypur (2012) - Starring: Anurag Kashyap (dir.), Manoj Bajpayee, Richa Chadha 8.151692643130689\n",
      "63 - Mandela (2021) - Starring: Madonne Ashwin (dir.), Yogi Babu, Sheela Rajkumar 8.149806572643513\n",
      "64 - Pithamagan (2003) - Starring: Bala (dir.), Vikram, Suriya 8.149482429261596\n",
      "65 - Jigarthanda (2014) - Starring: Karthik Subbaraj (dir.), Siddharth, Bobby Simha 8.148019223844578\n",
      "66 - Paan Singh Tomar (2012) - Starring: Tigmanshu Dhulia (dir.), Irrfan Khan, Mahie Gill 8.135813204180009\n",
      "67 - Bhaag Milkha Bhaag (2013) - Starring: Rakeysh Omprakash Mehra (dir.), Farhan Akhtar, Sonam Kapoor 8.131174956078285\n",
      "68 - Hera Pheri (2000) - Starring: Priyadarshan (dir.), Akshay Kumar, Suniel Shetty 8.1275145209996\n",
      "69 - Sairat (2016) - Starring: Nagraj Manjule (dir.), Rinku Rajguru, Akash Thosar 8.12657019406378\n",
      "70 - Sholay (1975) - Starring: Ramesh Sippy (dir.), Sanjeev Kumar, Dharmendra 8.123615150861779\n",
      "71 - Swades: We, the People (2004) - Starring: Ashutosh Gowariker (dir.), Shah Rukh Khan, Gayatri Joshi 8.121822366151735\n",
      "72 - Talvar (2015) - Starring: Meghna Gulzar (dir.), Irrfan Khan, Konkona Sen Sharma 8.119423950109645\n",
      "73 - Chak De! India (2007) - Starring: Shimit Amin (dir.), Shah Rukh Khan, Vidya Malvade 8.1194089356022\n",
      "74 - Maheshinte Prathikaaram (2016) - Starring: Dileesh Pothan (dir.), Fahadh Faasil, Aparna Balamurali 8.119265597091381\n",
      "75 - Ustad Hotel (2012) - Starring: Anwar Rasheed (dir.), Dulquer Salmaan, Thilakan 8.114761401581703\n",
      "76 - Mughal-E-Azam (1960) - Starring: K. Asif (dir.), Prithviraj Kapoor, Madhubala 8.113534679959908\n",
      "77 - Zindagi Na Milegi Dobara (2011) - Starring: Zoya Akhtar (dir.), Hrithik Roshan, Farhan Akhtar 8.111935311118975\n",
      "78 - Black (2005) - Starring: Sanjay Leela Bhansali (dir.), Amitabh Bachchan, Rani Mukerji 8.111748613914823\n",
      "79 - Drishyam (2015) - Starring: Nishikant Kamat (dir.), Ajay Devgn, Shriya Saran 8.110811322272943\n",
      "80 - Jo Jeeta Wohi Sikandar (1992) - Starring: Mansoor Khan (dir.), Aamir Khan, Ayesha Jhulka 8.109783351059859\n",
      "81 - Theeran adhigaaram ondru (2017) - Starring: H. Vinoth (dir.), Karthi, Rakul Preet Singh 8.108724696146387\n",
      "82 - Nil Battey Sannata (2015) - Starring: Ashwiny Iyer Tiwari (dir.), Swara Bhaskar, Ratna Pathak Shah 8.107766246938432\n",
      "83 - Chhichhore (2019) - Starring: Nitesh Tiwari (dir.), Sushant Singh Rajput, Shraddha Kapoor 8.106701531264445\n",
      "84 - Article 15 (2019) - Starring: Anubhav Sinha (dir.), Ayushmann Khurrana, Nassar 8.105815609561787\n",
      "85 - Charulata (1964) - Starring: Satyajit Ray (dir.), Soumitra Chatterjee, Madhabi Mukherjee 8.10530311220501\n",
      "86 - Udaan (2010) - Starring: Vikramaditya Motwane (dir.), Rajat Barmecha, Ronit Roy 8.104505746902134\n",
      "87 - A Wednesday (2008) - Starring: Neeraj Pandey (dir.), Anupam Kher, Naseeruddin Shah 8.101753138101492\n",
      "88 - Baasha (1995) - Starring: Suresh Krishna (dir.), Rajinikanth, Nagma 8.097175301095525\n",
      "89 - Alai Payuthey (2000) - Starring: Mani Ratnam (dir.), Madhavan, Shalini 8.095039362341788\n",
      "90 - Munna Bhai MBBS (2003) - Starring: Rajkumar Hirani (dir.), Sanjay Dutt, Arshad Warsi 8.095039249098681\n",
      "91 - Masaan (2015) - Starring: Neeraj Ghaywan (dir.), Richa Chadha, Sanjay Mishra 8.09474931936772\n",
      "92 - Sarfarosh (1999) - Starring: John Mathew Matthan (dir.), Aamir Khan, Naseeruddin Shah 8.091411747724258\n",
      "93 - Queen (2013) - Starring: Vikas Bahl (dir.), Kangana Ranaut, Rajkummar Rao 8.090485350490816\n",
      "94 - Virumandi (2004) - Starring: Kamal Haasan (dir.), Kamal Haasan, Abhirami 8.088559315301103\n",
      "95 - Dil Chahta Hai (2001) - Starring: Farhan Akhtar (dir.), Aamir Khan, Saif Ali Khan 8.086592227059061\n",
      "96 - Rang De Basanti (2006) - Starring: Rakeysh Omprakash Mehra (dir.), Aamir Khan, Soha Ali Khan 8.086247503036315\n",
      "97 - OMG: Oh My God! (2012) - Starring: Umesh Shukla (dir.), Paresh Rawal, Akshay Kumar 8.085213165540113\n",
      "98 - Roja (1992) - Starring: Mani Ratnam (dir.), Arvind Swamy, Madhoo 8.084441288414414\n",
      "99 - Uri: The Surgical Strike (2019) - Starring: Aditya Dhar (dir.), Vicky Kaushal, Paresh Rawal 8.077635090818374\n",
      "10 -  Lagaan: Once Upon a Time in India (2001) - Starring: Ashutosh Gowariker (dir.), Aamir Khan, Raghuvir Yadav 8.074907936058857\n",
      "101 - Andaz Apna Apna (1994) - Starring: Rajkumar Santoshi (dir.), Aamir Khan, Salman Khan 8.074018974696687\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "\n",
    "ratings = [b.attrs.get('data-value')\n",
    "\t\tfor b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "votes = [b.attrs.get('data-value')\n",
    "\t\tfor b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "list = []\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, 101):\n",
    "\t\n",
    "\t# Separating movie into: 'place',\n",
    "\t# 'title', 'year'\n",
    "\tmovie_string = movies[index].get_text()\n",
    "\tmovie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "\tmovie_title = movie[len(str(index))+1:-7]\n",
    "\tyear = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "\tplace = movie[:len(str(index))-(len(movie))]\n",
    "\tdata = {\"movie_title\": movie_title,\n",
    "\t\t\t\"year\": year,\n",
    "\t\t\t\"place\": place,\n",
    "\t\t\t\"star_cast\": crew[index],\n",
    "\t\t\t\"rating\": ratings[index],\n",
    "\t\t\t\"vote\": votes[index],\n",
    "\t\t\t\"link\": links[index]}\n",
    "\tlist.append(data)\n",
    "\n",
    "print('\\033[1m'+'IMDB’s Top rated 100 Indian movies'+'\\033[0m')\n",
    "# printing movie details with its rating.\n",
    "for movie in list:\n",
    "\tprint(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n",
    "\t\t') -', 'Starring:', movie['star_cast'], movie['rating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBook Review from Bookpage.com\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Author List</th>\n",
       "      <th>Book Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ A Calling for Charlie Barnes</td>\n",
       "      <td>[Fiction, Family Drama]</td>\n",
       "      <td>Joshua Ferris</td>\n",
       "      <td>How does one sum up the arc of a long life? Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playing the Cards You're Dealt</td>\n",
       "      <td>[Children's, Middle Grade]</td>\n",
       "      <td>Varian Johnson</td>\n",
       "      <td>It’s day one of fifth grade, and Anthony “Ant”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please Don't Sit on My Bed in Your Outside Clo...</td>\n",
       "      <td>[Nonfiction, Essays, Humor]</td>\n",
       "      <td>Phoebe Robinson</td>\n",
       "      <td>From dubbing Michael Keaton an “Eyebrow Zaddy”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horseman</td>\n",
       "      <td>[Science Fiction &amp; Fantasy, Fantasy, Historica...</td>\n",
       "      <td>Christina Henry</td>\n",
       "      <td>Christina Henry’s Horseman is an atmospheric a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>★ Cloud Cuckoo Land</td>\n",
       "      <td>[Fiction, Literary Fiction]</td>\n",
       "      <td>Anthony Doerr</td>\n",
       "      <td>Fans of Anthony Doerr’s Pulitzer Prize-winning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Book Title  \\\n",
       "0                     ★ A Calling for Charlie Barnes   \n",
       "1                     Playing the Cards You're Dealt   \n",
       "2  Please Don't Sit on My Bed in Your Outside Clo...   \n",
       "3                                           Horseman   \n",
       "4                                ★ Cloud Cuckoo Land   \n",
       "\n",
       "                                              Genres      Author List  \\\n",
       "0                            [Fiction, Family Drama]    Joshua Ferris   \n",
       "1                         [Children's, Middle Grade]   Varian Johnson   \n",
       "2                        [Nonfiction, Essays, Humor]  Phoebe Robinson   \n",
       "3  [Science Fiction & Fantasy, Fantasy, Historica...  Christina Henry   \n",
       "4                        [Fiction, Literary Fiction]    Anthony Doerr   \n",
       "\n",
       "                                         Book Review  \n",
       "0  How does one sum up the arc of a long life? Th...  \n",
       "1  It’s day one of fifth grade, and Anthony “Ant”...  \n",
       "2  From dubbing Michael Keaton an “Eyebrow Zaddy”...  \n",
       "3  Christina Henry’s Horseman is an atmospheric a...  \n",
       "4  Fans of Anthony Doerr’s Pulitzer Prize-winning...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "Bookpage_url = 'https://bookpage.com/reviews'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(Bookpage_url)\n",
    "\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "Title_block = soup.find_all('div',attrs={'class':'row-fluid article-row'})\n",
    "Author_block = soup.find_all('p',attrs={'class':'sans bold'})\n",
    "Url_block = soup.find_all('div',attrs={'class':'read-full'})\n",
    "\n",
    "# Creating Empty List\n",
    "Book_Title = []\n",
    "Genres =[]\n",
    "Author_List =[]\n",
    "Review =[]\n",
    "\n",
    "# Creating function to store book detail in empty list\n",
    "def get_data():\n",
    "    for t in Title_block[:5]:\n",
    "        Book_Title.append(t.find_all('a')[1].text)\n",
    "\n",
    "    for genre in title_block[:5]:\n",
    "        temp = []\n",
    "        all_genres_per_book = genre.find_all('a')[2:-1]\n",
    "        for all_g in all_genres_per_book:\n",
    "            temp.append(all_g.text)\n",
    "        Genres.append(temp)\n",
    "        \n",
    "    for a in Author_block[:5]:\n",
    "        Author_List.append(a.text.strip('\\n'))\n",
    "\n",
    "    for url in Url_block[:5]:\n",
    "        url_review = main_url.strip('/reviews') + url.a.get('href')\n",
    "\n",
    "        sauce_2 = urllib.request.urlopen(url_review).read()\n",
    "        soup_2 = BeautifulSoup(sauce_2,'html.parser')\n",
    "\n",
    "        Review.append(soup_2.find('div',attrs={'class':'article-body'}).text.strip('\\n'))\n",
    "            \n",
    "    book_review_df = pd.DataFrame({'Book Title': Book_Title,'Genres':Genres,'Author List':Author_List,'Book Review':Review})\n",
    "    \n",
    "    return book_review_df  \n",
    "       \n",
    "df = get_data()\n",
    "\n",
    "df.to_json('book_review.json',orient='records')\n",
    "df.to_csv('book_review.csv',index=False)\n",
    "\n",
    "print('\\033[1m'+'Book Review from Bookpage.com'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points andrating.\n",
    "\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "\n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Top 10 ODI teams in men’s cricket along with the records for matches, points andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
      "\n",
      "\n",
      "\u001b[1mICC MENS ODI RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>119</td>\n",
       "      <td>2,054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>116</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>3,793</td>\n",
       "      <td>113</td>\n",
       "      <td>3,793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>28</td>\n",
       "      <td>98</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>3,244</td>\n",
       "      <td>93</td>\n",
       "      <td>3,244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>32</td>\n",
       "      <td>91</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>3,624</td>\n",
       "      <td>84</td>\n",
       "      <td>3,624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2,459</td>\n",
       "      <td>62</td>\n",
       "      <td>2,459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Rating Points\n",
       "0   New Zealand      17    119  2,054\n",
       "1       England      32    116     32\n",
       "2     Australia   3,793    113  3,793\n",
       "3         India      28     98     28\n",
       "4  South Africa   3,244     93  3,244\n",
       "5      Pakistan      32     91     32\n",
       "6    Bangladesh   3,624     84  3,624\n",
       "7   West Indies      25     83     25\n",
       "8     Sri Lanka   2,459     62  2,459\n",
       "9   Afghanistan      27     48     27"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n')\n",
    "soup= BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "Country = soup.find_all('span',class_=\"u-hide-phablet\")\n",
    "for i in Country:\n",
    "    Team.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Team=Team[0:10]\n",
    "\n",
    "match=soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "matchs=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "mtc = match + matchs\n",
    "\n",
    "for i in mtc:\n",
    "    Matches.append(i.text)\n",
    "    Matches=Matches[0:10]\n",
    "    \n",
    "pt=soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "\n",
    "pts= soup.find_all('td',class_ =\"table-body__cell u-center-text\")\n",
    "Point= pt + pts\n",
    "for i in Point:\n",
    "    Points.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Points=Points[0:10]\n",
    "rating = soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in rating:\n",
    "    Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Rating=Rating[0:10]\n",
    "    \n",
    "ODI=pd.DataFrame({})\n",
    "ODI['Country']=Team\n",
    "ODI['Matches']=Matches\n",
    "ODI['Rating']=Rating\n",
    "ODI['Points']=Points\n",
    "print('\\033[1m'+'ICC MENS ODI RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI MENS BATTING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td></td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Ranking      Player_Name Team Rating\n",
       "0                                        1       Babar Azam         873\n",
       "1                                2              Virat Kohli  IND    844\n",
       "2                                3             Rohit Sharma  IND    813\n",
       "3                                4              Ross Taylor   NZ    801\n",
       "4                                5              Aaron Finch  AUS    779\n",
       "5                                6           Jonny Bairstow  ENG    775\n",
       "6                                7             David Warner  AUS    762\n",
       "7                                8                Shai Hope   WI    758\n",
       "8                                9          Kane Williamson   NZ    754\n",
       "9                               10          Quinton de Kock   SA    747\n",
       "10                              11             Fakhar Zaman  PAK    741"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC Bating Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup= BeautifulSoup(response.content, 'lxml')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Batmans=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI MENS BATTING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Batmans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI MENS BOWLING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td></td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Ranking        Player_Name Team Rating\n",
       "0                                        1        Trent Boult         737\n",
       "1                                2             Josh Hazlewood  AUS    709\n",
       "2                                3           Mujeeb Ur Rahman  AFG    708\n",
       "3                                4               Chris Woakes  ENG    700\n",
       "4                                5               Mehedi Hasan  BAN    692\n",
       "5                                6                 Matt Henry   NZ    691\n",
       "6                                7             Jasprit Bumrah  IND    679\n",
       "7                                8             Mitchell Starc  AUS    652\n",
       "8                                9            Shakib Al Hasan  BAN    650\n",
       "9                               10              Kagiso Rabada   SA    646\n",
       "10                              11          Mustafizur Rahman  BAN    640"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC ODI Mens Bowling Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup= BeautifulSoup(response.content, 'lxml')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Bowling=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI MENS BOWLING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Bowling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/womens/team-rankings/odi\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI WOMENS RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>161               ...</td>\n",
       "      <td>3,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>119</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>2,983</td>\n",
       "      <td>117</td>\n",
       "      <td>2,983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>3,390</td>\n",
       "      <td>92</td>\n",
       "      <td>3,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2,934</td>\n",
       "      <td>75</td>\n",
       "      <td>2,934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>2,392</td>\n",
       "      <td>47</td>\n",
       "      <td>2,392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches                                             Rating  \\\n",
       "0     Australia      21                              161               ...   \n",
       "1       England      25                                                119   \n",
       "2  South Africa   2,983                                                117   \n",
       "3         India      29                                                113   \n",
       "4   New Zealand   3,390                                                 92   \n",
       "5   West Indies      26                                                 85   \n",
       "6      Pakistan   2,934                                                 75   \n",
       "7    Bangladesh      26                                                 61   \n",
       "8     Sri Lanka   2,392                                                 47   \n",
       "9       Ireland      22                                                 13   \n",
       "\n",
       "  Points  \n",
       "0  3,379  \n",
       "1     25  \n",
       "2  2,983  \n",
       "3     29  \n",
       "4  3,390  \n",
       "5     26  \n",
       "6  2,934  \n",
       "7     26  \n",
       "8  2,392  \n",
       "9     22  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n')\n",
    "SOUP= BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "# Creating empty list\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "# Extracting Team Name\n",
    "Country = SOUP.find_all('span',class_=\"u-hide-phablet\")\n",
    "for i in Country:\n",
    "    Team.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Team=Team[0:10]\n",
    "    \n",
    "# Extracting No of Matches    \n",
    "match=SOUP.find_all('td',class_='rankings-block__banner--matches')\n",
    "matchs=SOUP.find_all('td',class_='table-body__cell u-center-text')\n",
    "mtc = match + matchs\n",
    "for i in  mtc:\n",
    "    Matches.append(i.text)\n",
    "    Matches=Matches[0:10]\n",
    "    \n",
    "# Extracting Points gain    \n",
    "pt=SOUP.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "pts= SOUP.find_all('td',class_ =\"table-body__cell u-center-text\")\n",
    "Point= pt + pts\n",
    "for i in Point:\n",
    "    Points.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Points=Points[0:10]\n",
    "    \n",
    "# Extracting Rating\n",
    "rat=SOUP.find_all('td',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "rating = SOUP.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "RATING=rat + rating\n",
    "for i in RATING:\n",
    "    Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Rating=Rating[0:10]\n",
    "Rating\n",
    "\n",
    "# Creating dataframe to store data\n",
    "ODI=pd.DataFrame({})\n",
    "ODI['Country']=Team\n",
    "ODI['Matches']=Matches\n",
    "ODI['Rating']=Rating\n",
    "ODI['Points']=Points\n",
    "\n",
    "print('\\033[1m'+'ICC ODI WOMENS RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI WOMENS BATTING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td></td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4        This play...</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5        This play...</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6        This play...</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7        This play...</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8        This play...</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9        This play...</td>\n",
       "      <td>Heather Knight</td>\n",
       "      <td>ENG</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        This pla...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        This pla...</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking        Player_Name Team  \\\n",
       "0                                                   1        Lizelle Lee        \n",
       "1                                           2               Alyssa Healy  AUS   \n",
       "2                                           3                Mithali Raj  IND   \n",
       "3                               4        This play...     Tammy Beaumont  ENG   \n",
       "4                               5        This play...  Amy Satterthwaite   NZ   \n",
       "5                               6        This play...    Smriti Mandhana  IND   \n",
       "6                               7        This play...        Meg Lanning  AUS   \n",
       "7                               8        This play...        Beth Mooney  AUS   \n",
       "8                               9        This play...     Heather Knight  ENG   \n",
       "9                               10        This pla...    Laura Wolvaardt   SA   \n",
       "10                              11        This pla...     Rachael Haynes  AUS   \n",
       "\n",
       "   Rating  \n",
       "0     761  \n",
       "1     750  \n",
       "2     738  \n",
       "3     728  \n",
       "4     717  \n",
       "5     710  \n",
       "6     699  \n",
       "7     690  \n",
       "8     674  \n",
       "9     672  \n",
       "10    668  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC WOMENS Bating Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup= BeautifulSoup(response.text, 'lxml')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Batmans=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI WOMENS BATTING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Batmans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI WOMENS BOWLING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td></td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2        This play...</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3        This play...</td>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4        This play...</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5        This play...</td>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6        This play...</td>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9        This play...</td>\n",
       "      <td>Anya Shrubsole</td>\n",
       "      <td>ENG</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        This pla...</td>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        This pla...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking        Player_Name Team  \\\n",
       "0                                                   1      Jess Jonassen        \n",
       "1                               2        This play...     Jhulan Goswami  IND   \n",
       "2                               3        This play...       Megan Schutt  AUS   \n",
       "3                               4        This play...     Marizanne Kapp   SA   \n",
       "4                               5        This play...  Sophie Ecclestone  ENG   \n",
       "5                               6        This play...     Shabnim Ismail   SA   \n",
       "6                                           7            Katherine Brunt  ENG   \n",
       "7                                           8             Ayabonga Khaka   SA   \n",
       "8                               9        This play...     Anya Shrubsole  ENG   \n",
       "9                               10        This pla...         Kate Cross  ENG   \n",
       "10                              11        This pla...     Natalie Sciver  ENG   \n",
       "\n",
       "   Rating  \n",
       "0     760  \n",
       "1     727  \n",
       "2     717  \n",
       "3     715  \n",
       "4     701  \n",
       "5     688  \n",
       "6     666  \n",
       "7     643  \n",
       "8     598  \n",
       "9     589  \n",
       "10    580  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC ODI Womens Bowling Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup= BeautifulSoup(response.text, 'html.parser')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Bowling=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI WOMENS BOWLING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Bowling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.amazon.in/best-mobile-under-20000/s?k=best+mobile+under+20000\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m Best Mobile phones under Rs. 20,000 listed on Amazon.in\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mobiles &amp; Smartphone</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>6999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>9499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>16999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi 9 Power (Mighty Black 4GB RAM 64GB Stora...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>11499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71hEzQGO5q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi 9A (Midnight Black, 2GB RAM, 32GB Storag...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>6999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>realme C11 (2021) (Cool Blue, 2GB RAM, 32GB St...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>7299</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71FYSKYFup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Redmi Note 10 (Aqua Green, 4GB RAM, 64GB Stora...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>13999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/810GQ7CWdD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Redmi Note 10 Pro Max (Dark Night, 6GB RAM, 12...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>19999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81Vpy0XrvF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>9499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716nHhG9SW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPPO A74 5G (Fantastic Purple,6GB RAM,128GB St...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>17990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71geVdy6-O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>13499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61LHaUOheh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>realme C11 (2021) (Cool Blue, 4GB RAM+64GB Sto...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>8799</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31RDanklxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>realme C11 (2021) (Cool Grey, 2GB RAM, 32GB St...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>7299</td>\n",
       "      <td>https://m.media-amazon.com/images/I/618UBhFmaQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Redmi 9 Power (Electric Green, 6GB RAM, 128GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>13499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61EIaUqatT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Redmi Note 10 Pro (Glacial Blue, 6GB RAM, 128G...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>17999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81nndQAg2n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OPPO A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>12990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61CnyJ-IbM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>4 Stars &amp; Up</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>3 Stars &amp; Up</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>2 Stars &amp; Up</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>1 Star &amp; Up</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Mobiles & Smartphone              Rating  \\\n",
       "0   Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...  4.2 out of 5 stars   \n",
       "1   Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....  4.2 out of 5 stars   \n",
       "2   Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...  4.2 out of 5 stars   \n",
       "3   Redmi 9 Power (Mighty Black 4GB RAM 64GB Stora...  4.2 out of 5 stars   \n",
       "4   Redmi 9A (Midnight Black, 2GB RAM, 32GB Storag...  4.3 out of 5 stars   \n",
       "5   realme C11 (2021) (Cool Blue, 2GB RAM, 32GB St...  4.1 out of 5 stars   \n",
       "6   Redmi Note 10 (Aqua Green, 4GB RAM, 64GB Stora...  4.2 out of 5 stars   \n",
       "7   Redmi Note 10 Pro Max (Dark Night, 6GB RAM, 12...  4.1 out of 5 stars   \n",
       "8   Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...  4.2 out of 5 stars   \n",
       "9   OPPO A74 5G (Fantastic Purple,6GB RAM,128GB St...  4.2 out of 5 stars   \n",
       "10  Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...  4.2 out of 5 stars   \n",
       "11  realme C11 (2021) (Cool Blue, 4GB RAM+64GB Sto...  3.5 out of 5 stars   \n",
       "12  realme C11 (2021) (Cool Grey, 2GB RAM, 32GB St...  4.1 out of 5 stars   \n",
       "13  Redmi 9 Power (Electric Green, 6GB RAM, 128GB ...  4.2 out of 5 stars   \n",
       "14  Redmi Note 10 Pro (Glacial Blue, 6GB RAM, 128G...  4.2 out of 5 stars   \n",
       "15  OPPO A31 (Fantasy White, 6GB RAM, 128GB Storag...  4.2 out of 5 stars   \n",
       "16                                               None        4 Stars & Up   \n",
       "17                                               None        3 Stars & Up   \n",
       "18                                               None        2 Stars & Up   \n",
       "19                                               None         1 Star & Up   \n",
       "\n",
       "    Price                                          Image_url  \n",
       "0    6999  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "1    9499  https://m.media-amazon.com/images/I/71A9Vo1Bat...  \n",
       "2   16999  https://m.media-amazon.com/images/I/71-Su4Wr0H...  \n",
       "3   11499  https://m.media-amazon.com/images/I/71hEzQGO5q...  \n",
       "4    6999  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "5    7299  https://m.media-amazon.com/images/I/71FYSKYFup...  \n",
       "6   13999  https://m.media-amazon.com/images/I/810GQ7CWdD...  \n",
       "7   19999  https://m.media-amazon.com/images/I/81Vpy0XrvF...  \n",
       "8    9499  https://m.media-amazon.com/images/I/716nHhG9SW...  \n",
       "9   17990  https://m.media-amazon.com/images/I/71geVdy6-O...  \n",
       "10  13499  https://m.media-amazon.com/images/I/61LHaUOheh...  \n",
       "11   8799  https://m.media-amazon.com/images/I/31RDanklxi...  \n",
       "12   7299  https://m.media-amazon.com/images/I/618UBhFmaQ...  \n",
       "13  13499  https://m.media-amazon.com/images/I/61EIaUqatT...  \n",
       "14  17999  https://m.media-amazon.com/images/I/81nndQAg2n...  \n",
       "15  12990  https://m.media-amazon.com/images/I/61CnyJ-IbM...  \n",
       "16   None                                               None  \n",
       "17   None                                               None  \n",
       "18   None                                               None  \n",
       "19   None                                               None  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.amazon.in/best-mobile-under-20000/s?k=best+mobile+under+20000'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup= BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#\n",
    "Product_block = soup.find_all('span', attrs={'class':'a-size-medium a-color-base a-text-normal'})\n",
    "Rating_block = soup.find_all('span', attrs={'class':'a-icon-alt'})\n",
    "Price_block = soup.find_all('span', attrs={'class':'a-price-whole'})\n",
    "image_url_block = soup.find_all('div', attrs={'class':\"a-section aok-relative s-image-fixed-height\"})\n",
    "\n",
    "# Creating Empty list\n",
    "Smartphone =[]\n",
    "Rating=[]\n",
    "Price =[]\n",
    "Img_url=[]\n",
    "\n",
    "# appending data in list\n",
    "Smartphone = [i.text for i in Product_block]\n",
    "Price = [int(j.text.replace(',','')) for j in Price_block]\n",
    "Rating = [k.text for k in Rating_block]\n",
    "Img_url =[img_url.img.get('src') for img_url in image_url_block]\n",
    "\n",
    "a ={'Mobiles & Smartphone':Smartphone,'Rating':Rating,'Price':Price,'Image_url':Img_url}\n",
    "df = pd.DataFrame.from_dict(a, orient='index')\n",
    "df = df.transpose()\n",
    "print('\\033[1m'+' Best Mobile phones under Rs. 20,000 listed on Amazon.in'+'\\033[0m')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSan Francisco 7-Day Weather Forecast\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Sky_View</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Detail Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TodaySunny,</td>\n",
       "      <td>TodaySunny</td>\n",
       "      <td>70</td>\n",
       "      <td>with a high near 70. Light  west wind increasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Tonight Mostly clear</td>\n",
       "      <td>55</td>\n",
       "      <td>Mostly clear, with a low around 55. West wind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ThursdaySunny,</td>\n",
       "      <td>ThursdaySunny</td>\n",
       "      <td>75</td>\n",
       "      <td>with a high near 75. Light  and variable wind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Thursday Night Increasing clouds</td>\n",
       "      <td>56</td>\n",
       "      <td>Night Increasing clouds, with a low around 56....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FridayMostly</td>\n",
       "      <td>FridayMostly sunny</td>\n",
       "      <td>73</td>\n",
       "      <td>sunny, with a high near 73. Light  west wind i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Friday Night Partly cloudy</td>\n",
       "      <td>55</td>\n",
       "      <td>Night Partly cloudy, with a low around 55.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday Mostly sunny</td>\n",
       "      <td>73</td>\n",
       "      <td>Mostly sunny, with a high near 73.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday Night Partly cloudy</td>\n",
       "      <td>55</td>\n",
       "      <td>Night Partly cloudy, with a low around 55.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday Sunny</td>\n",
       "      <td>73</td>\n",
       "      <td>Sunny, with a high near 73.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday Night Partly cloudy</td>\n",
       "      <td>56</td>\n",
       "      <td>Night Partly cloudy, with a low around 56.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday Mostly sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>Mostly sunny, with a high near 72.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday Night Partly cloudy</td>\n",
       "      <td>56</td>\n",
       "      <td>Night Partly cloudy, with a low around 56.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday Partly sunny</td>\n",
       "      <td>68</td>\n",
       "      <td>Partly sunny, with a high near 68.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Day                          Sky_View  Temperature  \\\n",
       "0      TodaySunny,                        TodaySunny           70   \n",
       "1          Tonight              Tonight Mostly clear           55   \n",
       "2   ThursdaySunny,                     ThursdaySunny           75   \n",
       "3         Thursday  Thursday Night Increasing clouds           56   \n",
       "4     FridayMostly                FridayMostly sunny           73   \n",
       "5           Friday        Friday Night Partly cloudy           55   \n",
       "6         Saturday             Saturday Mostly sunny           73   \n",
       "7         Saturday      Saturday Night Partly cloudy           55   \n",
       "8           Sunday                      Sunday Sunny           73   \n",
       "9           Sunday        Sunday Night Partly cloudy           56   \n",
       "10          Monday               Monday Mostly sunny           72   \n",
       "11          Monday        Monday Night Partly cloudy           56   \n",
       "12         Tuesday              Tuesday Partly sunny           68   \n",
       "\n",
       "                                      Detail Forecast  \n",
       "0   with a high near 70. Light  west wind increasi...  \n",
       "1   Mostly clear, with a low around 55. West wind ...  \n",
       "2   with a high near 75. Light  and variable wind ...  \n",
       "3   Night Increasing clouds, with a low around 56....  \n",
       "4   sunny, with a high near 73. Light  west wind i...  \n",
       "5          Night Partly cloudy, with a low around 55.  \n",
       "6                  Mostly sunny, with a high near 73.  \n",
       "7          Night Partly cloudy, with a low around 55.  \n",
       "8                         Sunny, with a high near 73.  \n",
       "9          Night Partly cloudy, with a low around 56.  \n",
       "10                 Mostly sunny, with a high near 72.  \n",
       "11         Night Partly cloudy, with a low around 56.  \n",
       "12                 Partly sunny, with a high near 68.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import re\n",
    "\n",
    "forcastpageContent=requests.get(\n",
    "     'https://forecast.weather.gov/MapClick.php?lat=37.77493000000004&lon=-122.41941999999995#.X7vZI1UzbIU'\n",
    ")\n",
    "\n",
    "tree = html.fromstring(forcastpageContent.content)\n",
    "\n",
    "Day = []\n",
    "Sky_View = []\n",
    "Temp = []\n",
    "Forecast = []\n",
    "\n",
    "for t in tree.xpath(\"//div[contains(@class,'row-forecast')]\"):\n",
    "    \n",
    "    if 'ight' in t.text_content():\n",
    "        temp = t.text_content().replace('ight','ight ')\n",
    "        Day.append(temp.split()[0])\n",
    "        Sky_View.append(temp.split(',')[0])\n",
    "        Temp.append(int(''.join(re.findall('[0-9]',temp))[:2]))\n",
    "        Forecast.append(''.join(temp.split(' ',maxsplit=1)[1:]))\n",
    "        \n",
    "    else:\n",
    "        temp = t.text_content().replace('day','day ')\n",
    "        Day.append(temp.split()[0])\n",
    "        Sky_View.append(temp.split(',')[0])\n",
    "        Temp.append(int(''.join(re.findall('[0-9]',temp))[:2]))\n",
    "        Forecast.append(''.join(temp.split(' ',maxsplit=1)[1:]))\n",
    "        \n",
    "San_Francisco_Weather = pd.DataFrame({'Day':Day,'Sky_View':Sky_View,'Temperature':Temp,'Detail Forecast':Forecast})\n",
    "print('\\033[1m'+'San Francisco 7-Day Weather Forecast'+'\\033[0m')\n",
    "San_Francisco_Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://internshala.com/internships/work-from-home-data%20science-jobs-in-mumbai\n",
      "\n",
      "\n",
      "\n",
      "40 40 40 40\n",
      "\u001b[1m Fresher job listings from ‘https://internshala.com/’\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Stipend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>Fashion TV            ...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2500-5000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Customaise Analytics P...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000-10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Research</td>\n",
       "      <td>Data Folkz            ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quantitative Research</td>\n",
       "      <td>AR Quants             ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>1000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Dascitech             ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Equity Research &amp; Fundamental Analysis</td>\n",
       "      <td>3C Capitals           ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Blackcoffer           ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000-10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research (ML/AI)</td>\n",
       "      <td>Madras Scientific Rese...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>Unpaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>Prakriti Textiles     ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Prakriti Textiles     ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Research Analysis</td>\n",
       "      <td>App Incubator Technolo...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>14000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Stylumia              ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>20000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scraping</td>\n",
       "      <td>Furballs Veterinary Cl...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>1000-3000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Reach Technologies    ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Python/Flask/SQLAlchemy Development</td>\n",
       "      <td>RedCarpetUp           ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>20000-25000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SAP Processing</td>\n",
       "      <td>INNOVAPTE             ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>1000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scraping &amp; Data Analytics</td>\n",
       "      <td>Sud Goyal             ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000-6500 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial Neural Networks</td>\n",
       "      <td>ROOT2AI Technology Pri...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>Unpaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Business Analytics</td>\n",
       "      <td>Edhub Alpha Private Li...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>20000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>Medius Technologies Pr...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DevOps Engineering</td>\n",
       "      <td>Helping Hand          ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>1000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Product Management</td>\n",
       "      <td>FactWise Tech         ...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>7000-12000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GIS Application Development</td>\n",
       "      <td>VNuIT India           ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>15000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Research (AI/ML)</td>\n",
       "      <td>Blackcoffer           ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Teaching (Data Science)</td>\n",
       "      <td>Unschool              ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>1500 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Management Trainee - Data Mining</td>\n",
       "      <td>EC-Council            ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>15000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>SPACE For Early Childh...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>Unpaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Business Analytics</td>\n",
       "      <td>Sharp ITech           ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>25000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Big Data Analytics</td>\n",
       "      <td>Substratal Solutions P...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>2000-3500 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Deep Learning Engineering</td>\n",
       "      <td>The Tann Mann Foundati...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>Unpaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>RanchPal              ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>4000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Machine Learning Cloud Operations</td>\n",
       "      <td>VPODS.ai              ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Research And Development</td>\n",
       "      <td>UPAY (Under Privileged...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>Unpaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Geoinformatics</td>\n",
       "      <td>NatureDots Private Lim...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>YouTube Analytics</td>\n",
       "      <td>Bollygrad Studioz     ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>4500-7000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Clavrit Digital Soluti...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>10000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Suvidha Foundation    ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>Unpaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Big Data Pipeline Development</td>\n",
       "      <td>VisionFirst Technologi...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>2000 /month +  Incentives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Pugalia Woollen Mills ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>1000 /month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>SkillBit              ...</td>\n",
       "      <td>Work From Home</td>\n",
       "      <td>5000 /month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Job Title  \\\n",
       "0                   Research & Development    \n",
       "1                             Data Science    \n",
       "2                    Data Science Research    \n",
       "3                    Quantitative Research    \n",
       "4                             Data Science    \n",
       "5   Equity Research & Fundamental Analysis    \n",
       "6                             Data Science    \n",
       "7                         Research (ML/AI)    \n",
       "8                           Data Analytics    \n",
       "9                             Data Science    \n",
       "10                       Research Analysis    \n",
       "11                            Data Science    \n",
       "12                           Data Scraping    \n",
       "13                            Data Science    \n",
       "14     Python/Flask/SQLAlchemy Development    \n",
       "15                          SAP Processing    \n",
       "16          Data Scraping & Data Analytics    \n",
       "17              Artificial Neural Networks    \n",
       "18                      Business Analytics    \n",
       "19                          Data Analytics    \n",
       "20                      DevOps Engineering    \n",
       "21                      Product Management    \n",
       "22             GIS Application Development    \n",
       "23                        Research (AI/ML)    \n",
       "24                 Teaching (Data Science)    \n",
       "25        Management Trainee - Data Mining    \n",
       "26                           Data Analysis    \n",
       "27                      Business Analytics    \n",
       "28                      Big Data Analytics    \n",
       "29               Deep Learning Engineering    \n",
       "30                        Machine Learning    \n",
       "31       Machine Learning Cloud Operations    \n",
       "32                Research And Development    \n",
       "33                          Geoinformatics    \n",
       "34                       YouTube Analytics    \n",
       "35                        Machine Learning    \n",
       "36                        Machine Learning    \n",
       "37           Big Data Pipeline Development    \n",
       "38                        Machine Learning    \n",
       "39                        Machine Learning    \n",
       "\n",
       "                                              Company        Location  \\\n",
       "0                           Fashion TV            ...          Mumbai   \n",
       "1                           Customaise Analytics P...  Work From Home   \n",
       "2                           Data Folkz            ...  Work From Home   \n",
       "3                           AR Quants             ...  Work From Home   \n",
       "4                           Dascitech             ...  Work From Home   \n",
       "5                           3C Capitals           ...  Work From Home   \n",
       "6                           Blackcoffer           ...  Work From Home   \n",
       "7                           Madras Scientific Rese...  Work From Home   \n",
       "8                           Prakriti Textiles     ...  Work From Home   \n",
       "9                           Prakriti Textiles     ...  Work From Home   \n",
       "10                          App Incubator Technolo...  Work From Home   \n",
       "11                          Stylumia              ...  Work From Home   \n",
       "12                          Furballs Veterinary Cl...  Work From Home   \n",
       "13                          Reach Technologies    ...  Work From Home   \n",
       "14                          RedCarpetUp           ...  Work From Home   \n",
       "15                          INNOVAPTE             ...  Work From Home   \n",
       "16                          Sud Goyal             ...  Work From Home   \n",
       "17                          ROOT2AI Technology Pri...  Work From Home   \n",
       "18                          Edhub Alpha Private Li...  Work From Home   \n",
       "19                          Medius Technologies Pr...          Mumbai   \n",
       "20                          Helping Hand          ...  Work From Home   \n",
       "21                          FactWise Tech         ...          Mumbai   \n",
       "22                          VNuIT India           ...  Work From Home   \n",
       "23                          Blackcoffer           ...  Work From Home   \n",
       "24                          Unschool              ...  Work From Home   \n",
       "25                          EC-Council            ...  Work From Home   \n",
       "26                          SPACE For Early Childh...  Work From Home   \n",
       "27                          Sharp ITech           ...  Work From Home   \n",
       "28                          Substratal Solutions P...  Work From Home   \n",
       "29                          The Tann Mann Foundati...  Work From Home   \n",
       "30                          RanchPal              ...  Work From Home   \n",
       "31                          VPODS.ai              ...  Work From Home   \n",
       "32                          UPAY (Under Privileged...  Work From Home   \n",
       "33                          NatureDots Private Lim...  Work From Home   \n",
       "34                          Bollygrad Studioz     ...  Work From Home   \n",
       "35                          Clavrit Digital Soluti...  Work From Home   \n",
       "36                          Suvidha Foundation    ...  Work From Home   \n",
       "37                          VisionFirst Technologi...  Work From Home   \n",
       "38                          Pugalia Woollen Mills ...  Work From Home   \n",
       "39                          SkillBit              ...  Work From Home   \n",
       "\n",
       "                       Stipend  \n",
       "0             2500-5000 /month  \n",
       "1            5000-10000 /month  \n",
       "2                 10000 /month  \n",
       "3                  1000 /month  \n",
       "4                  5000 /month  \n",
       "5                  5000 /month  \n",
       "6            5000-10000 /month  \n",
       "7                       Unpaid  \n",
       "8                 10000 /month  \n",
       "9                 10000 /month  \n",
       "10                14000 /month  \n",
       "11                20000 /month  \n",
       "12            1000-3000 /month  \n",
       "13                 5000 /month  \n",
       "14          20000-25000 /month  \n",
       "15                 1000 /month  \n",
       "16            5000-6500 /month  \n",
       "17                      Unpaid  \n",
       "18                20000 /month  \n",
       "19                10000 /month  \n",
       "20                 1000 /month  \n",
       "21           7000-12000 /month  \n",
       "22                15000 /month  \n",
       "23                 5000 /month  \n",
       "24                 1500 /month  \n",
       "25                15000 /month  \n",
       "26                      Unpaid  \n",
       "27                25000 /month  \n",
       "28            2000-3500 /month  \n",
       "29                      Unpaid  \n",
       "30                 4000 /month  \n",
       "31                10000 /month  \n",
       "32                      Unpaid  \n",
       "33                10000 /month  \n",
       "34            4500-7000 /month  \n",
       "35                10000 /month  \n",
       "36                      Unpaid  \n",
       "37   2000 /month +  Incentives  \n",
       "38                 1000 /month  \n",
       "39                 5000 /month  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://internshala.com/internships/work-from-home-data%20science-jobs-in-mumbai'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup= BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "Title_block = soup.find_all('div', {'class':'heading_4_5 profile'})\n",
    "Company_block = soup.find_all('a', {'class':'link_display_like_text'})\n",
    "Location_block = soup.find_all('a', {'class':'location_link'})\n",
    "CTC_block = soup.find_all('span', {'class':'stipend'})\n",
    "Date_block = soup.find_all('div', {'class':'apply_by'})\n",
    "\n",
    "\n",
    "\n",
    "Title =[]\n",
    "Company =[]\n",
    "Location =[]\n",
    "Stipend =[]\n",
    "\n",
    "\n",
    "# appending data in list\n",
    "Title = [i.text.strip('\\n') for i in Title_block]\n",
    "Company = [j.text.strip('\\n') for j in Company_block]\n",
    "Location = [k.text for k in Location_block]\n",
    "Stipend =[l.text for l in CTC_block]\n",
    "\n",
    "\n",
    "print(len(Title),len(Company),len(Location),len(Stipend))\n",
    "df = pd.DataFrame({'Job Title':Title,'Company':Company,'Location':Location,'Stipend':Stipend})\n",
    "print('\\033[1m'+' Fresher job listings from ‘https://internshala.com/’'+'\\033[0m')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 200 rows!!!\n",
      "10 rows added!!!\n",
      "20 rows added!!!\n",
      "30 rows added!!!\n",
      "40 rows added!!!\n",
      "50 rows added!!!\n",
      "60 rows added!!!\n",
      "70 rows added!!!\n",
      "80 rows added!!!\n",
      "90 rows added!!!\n",
      "100 rows added!!!\n",
      "110 rows added!!!\n",
      "120 rows added!!!\n",
      "130 rows added!!!\n",
      "140 rows added!!!\n",
      "150 rows added!!!\n",
      "160 rows added!!!\n",
      "170 rows added!!!\n",
      "180 rows added!!!\n",
      "190 rows added!!!\n",
      "200 rows added!!!\n",
      "File Exported Sucessfully!!!!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Creating time string to give fie name\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Creating empty list\n",
    "BHK = []\n",
    "Area = []\n",
    "Size = []\n",
    "Deposit = []\n",
    "Rent = []\n",
    "Type = []\n",
    "Age = []\n",
    "For = []\n",
    "Possesion = []\n",
    "\n",
    "# Function to scrape\n",
    "def scrape_NoBroker(n):\n",
    "    print(f'Exporting {n} rows!!!')\n",
    "\n",
    "    try:\n",
    "        for page in range(int(n / 10)):\n",
    "\n",
    "            try:\n",
    "                print(f'{(page + 1) * 10} rows added!!!')\n",
    "\n",
    "                # Requesting URL\n",
    "                url = requests.get(\n",
    "                    'https://www.nobroker.in/property/rent/pune/multiple?searchParam=W3sibGF0IjoxOC41MDE4MzIyLCJsb24iOjczLjg2MzU5MTIsInBsYWNlSWQiOiJDaElKeFJnWkp4VEF3anNSUDAxSkREX21QUG8iLCJwbGFjZU5hbWUiOiJTd2FyZ2F0ZSJ9LHsibGF0IjoxOC40NTI5MzIyLCJsb24iOjczLjg2NTIzNzk5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSmgxOWxBY0hxd2pzUnlKb00xaUFLVzh3IiwicGxhY2VOYW1lIjoiS2F0cmFqIn0seyJsYXQiOjE4LjUzMTQ0MTksImxvbiI6NzMuODQ0NTYxNywicGxhY2VJZCI6IkNoSUpkMUY0SFhuQXdqc1J5RDEweW9GcTJDQSIsInBsYWNlTmFtZSI6IlNoaXZhamluYWdhciJ9XQ==&radius=2.0&sharedAccomodation=0' + str(\n",
    "                        page)).text\n",
    "\n",
    "                # Converting from HTML tag to BeautifulSoup object\n",
    "                soup = BeautifulSoup(url, 'lxml')\n",
    "\n",
    "                # Finding all the div tag wich contains all the info\n",
    "                houses = soup.find_all('div', class_='card')\n",
    "\n",
    "                # Looping through each div tag to get individual content\n",
    "                for house in houses:\n",
    "                    BHK.append(house.find('a', class_='card-link-detail')['title'][:1])\n",
    "                    Area_raw = house.find('a', class_='card-link-detail')['title']\n",
    "                    if ',' in Area_raw:\n",
    "                        Area.append(Area_raw.split(',')[-1])\n",
    "                    else:\n",
    "                        Area.append(Area_raw.split('in', 1)[-1])\n",
    "                        Size.append(house.find_all('meta', itemprop='value')[0]['content'])\n",
    "                        Deposit.append(house.find_all('meta', itemprop='value')[1]['content'])\n",
    "                        Rent.append(house.find_all('meta', itemprop='value')[2]['content'])\n",
    "                        Type.append(house.find_all('h5', class_=\"semi-bold\")[0].text)\n",
    "                        Age.append(house.find_all('h5', class_=\"semi-bold\")[1].text)\n",
    "                        For.append(house.find_all('h5', class_=\"semi-bold\")[2].text.replace('\\n', ''))\n",
    "                        Possesion.append(house.find_all('h5', class_=\"semi-bold\")[3].text.replace('\\n', ''))\n",
    "                        \n",
    "            except:\n",
    "                print(f'Row number {(page + 1) * 10} failed. Trying next one!!!')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Creating DataFrame and storing data\n",
    "    df = pd.DataFrame(list(zip(BHK, Area, Size, Deposit, Rent, Type, Age, For, Possesion, Link)),\n",
    "                      columns=['BHK', 'Address','Size(Acres)', 'Deposit(Rs)', 'Rent(Rs)',\n",
    "                               'Furnishing', 'Property Age', 'Available For', ' Immediate Possesion'])\n",
    "\n",
    "    # Exporting DataFrame in form of CSV file\n",
    "    File_name = \"House_Data_\" + timestr + \".csv\"\n",
    "    df.to_csv(File_name, index=False)\n",
    "    print(\"File Exported Sucessfully!!!!\")\n",
    "\n",
    "# Calling fuction to export data\n",
    "scrape_NoBroker(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
